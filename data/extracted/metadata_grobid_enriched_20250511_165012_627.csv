title,data_used,models_used,tools_used,keywords,participants,participants_count,biological_data,physiological_data,methodology,transparency,accuracy,purposivity,utility,propriety,accessibility,specificity,score_tapupas,population,intervention,comparison,outcome,score_pico,casp_clear_aim,casp_methodology,casp_recruitment,casp_ethics,casp_analysis,casp_results_stated,casp_value,casp_clear_aim_score,casp_clear_aim_pass,casp_methodology_score,casp_methodology_pass,casp_recruitment_score,casp_recruitment_pass,casp_ethics_score,casp_ethics_pass,casp_analysis_score,casp_analysis_pass,casp_results_stated_score,casp_results_stated_pass,casp_value_score,casp_value_pass,score_casp,kitch_research_question,kitch_study_context,kitch_data_collection,kitch_data_analysis,kitch_validity,kitch_replication,kitch_contribution,kitch_research_question_score,kitch_research_question_pass,kitch_search_strategy_score,kitch_search_strategy_pass,kitch_inclusion_criteria_score,kitch_inclusion_criteria_pass,kitch_data_extraction_score,kitch_data_extraction_pass,kitch_quality_assessment_score,kitch_quality_assessment_pass,kitch_data_synthesis_score,kitch_data_synthesis_pass,kitch_limitations_score,kitch_limitations_pass,score_kitchenham,score_prisma,prisma_objective_pass,prisma_eligibility_criteria_pass,prisma_information_sources_pass,prisma_search_strategy_pass,prisma_selection_process_pass,prisma_data_collection_pass,prisma_risk_of_bias_pass,prisma_synthesis_pass,prisma_limitations_pass,prisma_registration_pass,title_source,authors,abstract,abstract_length,doi,year,journal,keywords,target_education_level,countries,source_file
Risks of AI-Assisted Learning on Student Critical Thinking: A Case Study of Albania,,chatgpt; deep learning; gan; gat; gpt; ppo,aws; excel; numbers; processing; r; unity,Technology Risk; Ethics; Cognitive Development; Pedagogical Implications; Educational Technology; Cognitive Load; Decision-making; Learning Outcomes; Ethical Considerations,learners; participants; respondents; students; subjects; teachers,53,rna,erp; imu,qualitative,1,1,2,1,1,0,3,,students,a focused examination of ai-as,compromising their foundationa,,,True,True,False,False,False,True,True,0.94,,0.763,,0.724,,0.73,,0.563,,0.876,,0.924,,,False,True,True,False,False,False,False,0.84,True,0.789,True,0.871,True,0.768,True,0.883,True,0.785,True,0.85,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Eriona Çela; Mathias Fonkam; Rajasekhara Mouly Potluri,"
 Artificial Intelligence (AI) has increasingly become a transformative force in the education sector, offering unprecedented opportunities to enhance learning experiences and outcomes. This study examines the potential adverse effects of AI-assisted learning on critical cognitive skills, particularly critical thinking and problem-solving, within the context of Albania's educational landscape. Employing a quantitative methodology, a survey of 53 students was conducted across a private educational institution in Albania to gather data on their experiences and perceptions regarding AI-assisted learning. The findings indicate no significant difference in critical thinking skills between students with prior exposure to AI tools and those without. However, there is a statistically significant negative correlation between reliance on AI tools for assignments and students' problem-solving skills, suggesting that excessive dependence on AI can hinder the development of independent problemsolving abilities. Conversely, a strong positive correlation was found between the frequency of AI tool usage and students' perceptions of academic performance and assignment efficiency, highlighting the potential benefits of AI in enhancing these aspects of the educational experience. These results emphasize the need for a balanced integration of AI tools in education to ensure they complement rather than replace traditional learning methods. The study's findings have significant implications for educators and policymakers, suggesting that while AI can enhance certain educational outcomes, it is essential to address its potential risks to promote the development of essential cognitive skills. Future research should focus on larger, more diverse samples, incorporate objective measures of cognitive skills, and explore the long-term impacts of AI-assisted learning. 
",250,10.4018/IJRCM.350185,,,Technology Risk; Ethics; Cognitive Development; Pedagogical Implications; Educational Technology; Cognitive Load; Decision-making; Learning Outcomes; Ethical Considerations,college; graduate; graduate students; high school; higher education; undergrad; undergraduate; university,albania; india; iran; italy; kazakhstan; niger; nigeria; uk,2024_-_Risks_of_AI-Assisted_Learning_on_Student_Critical_Thinking-.pdf
Generative AI and Its Impact on Personalized Intelligent Tutoring Systems,dataset; eda; training data,chatgpt; gat; gpt; gpt-4; language model; large language model; llm; ppo,processing; r,,learners; students; subjects,,,affective computing; eda; emotional state; erp; imu,unknown,0,0,0,0,1,0,0,,learners,complex problem-solving proces,sufficient human oversight can,,,True,True,False,False,False,True,True,0.936,,0.769,,0.738,,0.732,,0.578,,0.852,,0.905,,,False,False,False,False,False,False,False,0.855,True,0.82,True,0.867,True,0.797,True,0.876,True,0.796,True,0.837,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Subhankar Maity; Aniket Deroy,"
 Generative Artificial Intelligence (AI) is revolutionizing educational technology by enabling highly personalized and adaptive learning environments within Intelligent Tutoring Systems (ITS). This report delves into the integration of Generative AI, particularly large language models (LLMs) like GPT-4, into ITS to enhance personalized education through dynamic content generation, real-time feedback, and adaptive learning pathways. We explore key applications such as automated question generation, customized feedback mechanisms, and interactive dialogue systems that respond to individual learner needs. The report also addresses significant challenges, including ensuring pedagogical accuracy, mitigating inherent biases in AI models, and maintaining learner engagement. Future directions highlight the potential advancements in multimodal AI integration, emotional intelligence in tutoring systems, and the ethical implications of AI-driven education. By synthesizing current research and practical implementations, this report underscores the transformative potential of Generative AI in creating more effective, equitable, and engaging educational experiences. 
",142,10.5281/zenodo.12730013,2024,,,,,2024_-_Generative_AI_and_Its_Impact_on_Personalized_Intelligent_Tutoring_Systems.pdf
Generative AI in Education: Perspectives Through an Academic Lens,data collection; dataset; eda,chatgpt; gan; gat; gpt; gpt-3; gpt-3.5; gpt-4; language model; large language model; llm; ppo; transformer; transformer model,cohere; excel; gensim; github; nltk; pandas; processing; python; r; textblob; unity,"Întorsureanu, I.; Oprea, S.-V.; Bâra, A.; Vespan, D. Generative education; gen-AI; large language models; bibliometrics; technologyenhanced learning",learners; students; subjects; teachers,,rna,cognitive load; eda; erp; imu,qualitative,1,0,0,0,0,0,1,,teachers,better conversational abilitie,any vendor-related limitations,,,True,False,False,False,False,True,True,0.931,,0.743,,0.704,,0.725,,0.576,,0.88,,0.92,,,True,False,False,True,False,False,True,0.834,True,0.754,True,0.856,True,0.753,True,0.876,True,0.768,True,0.837,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Marko Horvat; Tomislav Jagušt; Iulian Întorsureanu; Simona-Vasilica Oprea; Adela Bâra; Dragos; Vespan,"
 In this paper, we investigated the role of generative AI in education in academic publications extracted from Web of Science (3506 records; 2019-2024). The proposed methodology included three main streams: (1) Monthly analysis trends; top-ranking research areas, keywords and universities; frequency of keywords over time; a keyword co-occurrence map; collaboration networks; and a Sankey diagram illustrating the relationship between AI-related terms, publication years and research areas; (2) Sentiment analysis using a custom list of words, VADER and TextBlob; (3) Topic modeling using Latent Dirichlet Allocation (LDA). Terms such as ""artificial intelligence"" and ""generative artificial intelligence"" were predominant, but they diverged and evolved over time. By 2024, AI applications had branched into specialized fields, including education and educational research, computer science, engineering, psychology, medical informatics, healthcare sciences, general medicine and surgery. The sentiment analysis reveals a growing optimism in academic publications regarding generative AI in education, with a steady increase in positive sentiment from 2023 to 2024, while maintaining a predominantly neutral tone. Five main topics were derived from AI applications in education, based on an analysis of the most relevant terms extracted by LDA: (1) Gen-AI's impact in education and research; (2) ChatGPT as a tool for university students and teachers; (3) Large language models (LLMs) and prompting in computing education; (4) Applications of ChatGPT in patient education; (5) ChatGPT's performance in medical examinations. The research identified several emerging topics: discipline-specific application of LLMs, multimodal gen-AI, personalized learning, AI as a peer or tutor and cross-cultural and multilingual tools aimed at developing culturally relevant educational content and supporting the teaching of lesser-known languages. Further, gamification with generative AI involves designing interactive storytelling and adaptive educational games to enhance engagement and hybrid human-AI classrooms explore co-teaching dynamics, teacher-student relationships and the impact on classroom authority. 
",294,10.3390/electronics14051053,2025,,"Întorsureanu, I.; Oprea, S.-V.; Bâra, A.; Vespan, D. Generative education; gen-AI; large language models; bibliometrics; technologyenhanced learning",college; higher education; k-12; university,australia; china; indonesia; singapore; united states,2025_-__Generative_AI_in_Education-_Perspectives_Through_an_Academic_Lens_.pdf
Artificial intelligence in education: A systematic literature review,data collection; dataset; eda,chatgpt; decision tree; deep learning; gat; gpt; gpt-4; machine learning model; naive bayes; neural net; neural network; ppo; reinforcement learning; support vector machine,aws; cohere; excel; numbers; processing; r,,learners; students; subjects; teachers,24,rna,cognitive load; eda; emotional state; erp; imu,qualitative,2,2,0,1,0,0,3,,subjects,information systems,keywords plus,concentration,,True,True,False,False,False,True,True,0.927,,0.79,,0.71,,0.712,,0.608,,0.883,,0.919,,,True,False,True,False,False,False,False,0.847,True,0.792,True,0.863,True,0.782,True,0.879,True,0.796,True,0.848,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Shan Wang; Fang Wang; Zhen Zhu; Jingxuan Wang; Tam Tran; Zhao Du,"
 Artificial intelligence (AI) in education (AIED) has evolved into a substantial body of literature with diverse perspectives. In this review paper, we seek insights into three critical questions: (1) What are the primary categories of AI applications explored in the education field? (2) What are the predominant research topics and their key findings? (3) What is the status of major research design elements, including guiding theories, methodologies, and research contexts? A bibliometric analysis of 2,223 research articles followed by a content analysis of selected 125 papers reveals a comprehensive conceptual structure of the existing literature. The extant AIED research spans a wide spectrum of applications, encompassing those for adaptive learning and personalized tutoring, intelligent assessment and management, profiling and prediction, and emerging products. Research topics delve into both the technical design of education systems and the examination of the adoption, impacts, and challenges associated with AIED. Furthermore, this review highlights the diverse range of theories applied in the AIED literature, the multidisciplinary nature of publication venues, and underexplored research areas. In sum, this research offers valuable insights for interested scholars to comprehend the current state of AIED research and identify future research opportunities in this dynamic field. 
",197,10.1016/j.eswa.2024.124167,2024,,,college; distance education; higher education; k-12; k12; lifelong learning; online learning; preschool,china; mali,2024_-_Artificial_intelligence_in_education-_A_systematic_literature_review.pdf
"Varghese NN, Jose B, Bindhumol T, Cleetus A and Nair SB ( ) The power duo: unleashing cognitive potential through human-AI synergy in STEM and non-STEM education",eda,gat; ppo,excel; processing; r,STEM and non-STEM education; AI integration in education; critical thinking; human-AI collaboration; algorithmic transparency,learners; students; subjects; teachers,,rna,eda; erp; imu,quantitative,1,1,0,1,0,0,0,,learners,personalized tutoring,interpretative,and applied properly,,True,True,False,False,False,True,True,0.914,,0.767,,0.715,,0.698,,0.554,,0.853,,0.889,,,False,False,False,False,False,False,False,0.831,True,0.792,True,0.847,True,0.753,True,0.841,True,0.773,True,0.883,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Stefano Triberti; Ozden Sengul; Binny Jose; Nidhu Neena Varghese; T Bindhumol; Anu Cleetus; S Brinda Nair,"
 Bridging intelligence: a literature review on AI-human synergy in education 
 Theoretical perspectives on AI in education Learning theories offer a framework for understanding AI's application in education. In the context of Bloom's Taxonomy, AI can support lower-order thinking skills (knowledge, comprehension, application) in STEM education but lags in supporting higher-order skills Frontiers in Education frontiersin.org 
",55,10.1051/e3sconf/202345106011,,,STEM and non-STEM education; AI integration in education; critical thinking; human-AI collaboration; algorithmic transparency,,china; georgia; uk,2025_-__The_Role_of_Artificial_Intelligence_in_Computer_Science_Education-_A_Systematic_Review_with_a_Focus_on_Database.pdf
The Role of AI-Assisted Learning in Academic Writing: A Mixed-Methods Study on Chinese as a Second Language Students,data collection; eda; test data,chatgpt; gan; gat; gpt; llm; ppo,aws; cohere; excel; r,academic writing; Chinese as a second language; AI-assisted learning; mixedmethods study,learners; participants; students; teachers,6,rna,eda; erp,qualitative,4,1,0,0,0,0,2,,students,the increasingly widespread av,their counterparts in a tradit,each writing sample at the pre,,True,False,False,False,False,True,True,0.922,,0.749,,0.704,,0.7,,0.578,,0.866,,0.903,,,True,True,True,True,False,False,False,0.838,True,0.779,True,0.846,True,0.757,True,0.859,True,0.774,True,0.857,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Chen Chen; Frank Gong,"
 The Role of AI-Assisted Learning in Academic Writing: A Mixed-Methods Study on Chinese as a Second Language Students. Education Sciences, 15(2), 141. 
",22,10.3390/educsci15020141,2025,,academic writing; Chinese as a second language; AI-assisted learning; mixedmethods study,college; graduate; higher education; undergrad; undergraduate; university,china; colombia; egypt; indonesia; italy; kazakhstan; mali; niger; nigeria; thailand; vietnam,2025_-__The_Role_of_AI-Assisted_Learning_in_Academic_Writing-_A_Mixed-Methods_Study_on_Chinese_as_a_Second_Language_Students_.pdf
"AI and peer reviews in higher education: students' multimodal views on benefits, differences and limitations",data collection; eda; facial expression,chatgpt; gan; gat; gpt; gpt-3; language model; large language model; llm; ppo,cohere; excel; processing; r; unity,Generative AI; AI feedback; peer reviews; higher education,learners; participants; students; teachers,15,rna,eda; erp; imu,qualitative,3,1,1,0,0,0,2,,teachers,the potential for scalability,peer feedback,and the overall objective to b,,True,False,False,False,False,True,True,0.934,,0.733,,0.717,,0.705,,0.546,,0.87,,0.911,,,True,False,True,False,False,False,False,0.841,True,0.768,True,0.856,True,0.752,True,0.866,True,0.758,True,0.869,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Gabriela C Zapata; Bill Cope; Mary Kalantzis; Anastasia Olga; Olnancy Tzirides; Akash Kumar Saini; Duane Searsmith; Jennifer Whiting; Nikoleta Polyxeni Kastania; Vania Castro; Theodora Kourkoulou; John W Jones; Rodrigo Abrantes Da Silva; Nikoleta Polyxeni Kastania,"
 Since the launch of ChatGPT in November 2022, educational researchers and practitioners have sought to understand the ways in which these new generative AI technologies might influence education. This article describes one such effort. The focus of the investigation was chatbots responding from large language models to the review of open-ended student work. Specifically, the authors examined university students' multimodal views of the benefits and limitations of AI reviews as compared to human feedback. The participants were postgraduate students in a public American university. The students' opinions of their experiences with both types of reviews were expressed linguistically, visually and gesturally, and they were submitted to discursive and socio-semiotic analyses. The results revealed a preference for human reviews. Nevertheless, the participants also identified several benefits for AI feedback, as well as ways in which it had complemented human reviews, overwhelmingly welcoming its addition as part of their educational experience. 
",149,10.1080/1475939X.2025.2480807,,,Generative AI; AI feedback; peer reviews; higher education,college; graduate; graduate students; high school; higher education; online learning; postgraduate; university,japan; united states,2025_-_AI_and_Peer_Reviews_in_Higher_Education-_Students'_Multimodal_Views.pdf
"Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000",data collection; data sample; data set; dataset; ecg; eda; eeg; electrodermal activity; emg; emotion detection; eye movement; eye tracking; eye-tracking; facial expression; gaze data; heart rate; motion sensor; physiological data; raw data; saccade; sensor data; skin conductance,alexnet; autoencoder; cnn; convolutional neural network; deep learning; deep learning model; denoising autoencoder; gat; gru; lstm; machine learning model; mobilenet; neural net; neural network; ppo; recurrent neural network; reinforcement learning; resnet; rnn; svm; transformer; transformer model; transformers,notion; processing; r,,learners; participants; students,3,rna,affective computing; cognitive load; ecg; eda; eeg; electrodermal activity; emg; emotional arousal; emotional state; erp; eye movement; fixation; focus level; gsr; heart rate; imu; physiological data; saccade; sensor data; skin conductance; skin temperature,quantitative,2,1,1,0,1,1,1,,students,the text,examining the emotional dimens,reading engagement and compreh,,True,True,False,False,False,True,True,0.941,,0.763,,0.722,,0.735,,0.572,,0.884,,0.927,,,True,True,True,True,False,False,False,0.849,True,0.792,True,0.871,True,0.789,True,0.882,True,0.798,True,0.842,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Jayasankar Santhosh; Akshay Palimar Pai,"
 Engagement and emotion are critical components that significantly influence a reader's experience during a reading task. The level of engagement reflects the extent to which a reader is immersed and attentive to the content, while emotion represents the affective responses evoked by the text. The present study aims to detect the engagement and emotion levels during a reading task by leveraging the power of state-of-the-art deep learning models and investigating the correlations between the engagement levels and emotions. An experiment was conducted involving 18 university students reading 14 documents followed by a questionnaire to rate their levels of engagement, valence, and arousal after reading each document. A Tobii 4C eye-tracker with a pro license along with an Empatica E4 wristband were utilized to record the data from the participants. A range of deep learning models were utilized for computing the engagement, valence, and arousal values, employing both user-independent and user-dependent methods. Notably, the Transformer model exhibited better performance in terms of accuracy and F1-score in the context of userindependent approaches, while the Resnet model excelled when adopting the user-dependent approach. The recorded data was also utilized to establish the relationship between engagement levels and emotional states concerning the specific document being read. The prediction results were utilized to develop an interactive and user-friendly application designed to provide a visual representation of a reader's engagement level and emotional state while performing a reading task. The dashboard features an engagement gauge that displays the reader's level of engagement based on predicted class probabilities, and an emotion emoji serving as a visual cue that illustrates the predicted emotional state of the reader. 
",269,10.1109/ACCESS.2024.3350745,,,,master's degree; university,,2023_-_Toward_an_Interactive_Reading_Experience_Deep_Lear.pdf
The cognitive paradox of AI in education: between enhancement and erosion,dataset; eda,bert; chatgpt; deep learning; gpt; gpt-3; ppo,r; unity,artificial intelligence in education; Cognitive Load Theory; AI and critical thinking; self-determination theory; AI-driven learning strategies,learners; participants; respondents; students; teachers,,rna,cognitive load; eda; erp; fixation; imu,quantitative,0,0,0,0,0,0,0,,learners,unparalleled levels of persona,jeopardizing fundamental cogni,retention and engagement,,True,False,False,False,False,True,True,0.924,,0.748,,0.71,,0.691,,0.532,,0.852,,0.893,,,False,False,False,False,False,False,False,0.825,True,0.787,True,0.838,True,0.746,False,0.849,True,0.768,True,0.875,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Luwei Xiao; Catalin Vrabie; Binny Jose; Jaya Cherian; Alie Molly Verghis; Mary Sony; Sibichan Varghise; Joseph,,0,10.48550/arXiv.2412.13487,,,artificial intelligence in education; Cognitive Load Theory; AI and critical thinking; self-determination theory; AI-driven learning strategies,graduate; graduate students; high school; undergrad; undergraduate; undergraduate students; university,niger; nigeria; united states,2025_-_The_cognitive_paradox_of_AI_in_education-_between_enhancement_and_erosion.pdf
A Deep Learning-Based Approach to Video-Based Eye Tracking for Human Psychophysics,dataset; eye tracking; eye-tracking; gaze position; raw data; test data; validation data,convolutional neural network; deep learning; neural net; neural network; ppo,github; processing; pytorch; r; torch,deep learning; eye tracking; gaze tracking; artificial intelligence; DeepLabCut; human psychophysics,subjects,200,rna,erp; imu,quantitative,0,0,1,0,1,0,0,,subjects,more than a single infrared so,other approaches that are appr,by extracting a set of,,True,False,False,False,False,True,True,0.935,,0.708,,0.693,,0.718,,0.529,,0.873,,0.915,,,False,False,False,False,False,False,True,0.823,True,0.747,False,0.838,True,0.761,True,0.877,True,0.761,True,0.815,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Niklas Zdarsky; Stefan Treue; Moein Esghaei,"
 Real-time gaze tracking provides crucial input to psychophysics studies and neuromarketing applications. Many of the modern eye-tracking solutions are expensive mainly due to the high-end processing hardware specialized for processing infraredcamera pictures. Here, we introduce a deep learning-based approach which uses the video frames of low-cost web cameras. Using DeepLabCut (DLC), an open-source toolbox for extracting points of interest from videos, we obtained facial landmarks critical to gaze location and estimated the point of gaze on a computer screen via a shallow neural network. Tested for three extreme poses, this architecture reached a median error of about one degree of visual angle. Our results contribute to the growing field of deeplearning approaches to eye-tracking, laying the foundation for further investigation by researchers in psychophysics or neuromarketing. 
",126,10.3389/fnhum.2021.685830,2021,,deep learning; eye tracking; gaze tracking; artificial intelligence; DeepLabCut; human psychophysics,university,canada; germany; sweden; switzerland; united states,2021_A_Deep_Learning-Based_Approach_to_Video-Based_Eye_Tracking_for_Human_Psychophysics..pdf
Real-time Adaptive Learning Environments Using Gaze and Emotion Recognition Engagement and Learning Outcomes,biometric data; data collection; eye movement; eye tracking; eye-tracking; facial emotion; facial expression; heart rate,gat,openface; postgresql; processing; r,Adaptive Learning; Gaze Tracking; Emotion Recognition; Student Engagement; Artificial Intelligence in Education,learners; participants; students,,,biometric data; emotional state; erp; eye movement; heart rate,qualitative,1,1,0,0,0,0,2,,students,automated communication strate,traditional instructional meth,by how the peter conversationa,,True,True,False,False,False,True,True,0.909,,0.8,,0.714,,0.722,,0.59,,0.869,,0.905,,,True,False,True,True,False,False,False,0.834,True,0.815,True,0.854,True,0.787,True,0.861,True,0.814,True,0.848,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Aboulhassane Cisse,"
 This study explores the integration of real-time adaptive learning environments with gaze tracking and emotion recognition technologies to enhance student engagement and learning outcomes. By leveraging artificial intelligence (AI) and machine learning, the research aims to develop a framework that dynamically adjusts instructional strategies based on students' cognitive and emotional states. The focus is on three objectives: integrating these technologies, evaluating their impact, and assessing the effectiveness of automated communication strategies-Affective Backchannels (AB), Conversational Strategies (CS), and their combination (AB+CS). Using a mixed-methods approach, data from approximately 30 university students in digital learning environments will be analyzed. The findings are expected to provide valuable insights into the application of these technologies in education, potentially informing future educational policies and practices. 
",120,,,,Adaptive Learning; Gaze Tracking; Emotion Recognition; Student Engagement; Artificial Intelligence in Education,university,mali,2024_ICCE2024-Paper_244_-_Camera_ready_-_AboulHassane_CISSE.pdf
Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy,data collection; dataset; emotion detection; eye-tracking; facial expression; physiological data,cnn; convolutional neural network; deep learning; gat; lstm; mobilenet; neural net; neural network; ppo; recurrent neural network; reinforcement learning; rnn; transformer; transformers,excel; processing; r,Human-in-the-loop; Engagement recognition; Computer vision,participants; students,112,rna,blink rate; cognitive load; emotional state; erp; imu; physiological data,qualitative,1,3,1,0,1,0,2,,students,data such as facial expression,,the accuracy of emotion recogn,,True,True,False,False,False,True,True,0.928,,0.779,,0.724,,0.747,,0.569,,0.878,,0.923,,,True,False,True,False,False,False,True,0.843,True,0.791,True,0.873,True,0.78,True,0.872,True,0.79,True,0.85,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Sahana Yadnakudige Subramanya; Ko Watanabe,"
 Human-in-the-loop (HITL) frameworks are increasingly recognized for their potential to improve annotation accuracy in emotion estimation systems by combining machine predictions with human expertise. This study focuses on integrating a high-performing image-based emotion model into a HITL annotation framework to evaluate humanmachine interaction's collaborative potential and uncover the psychological and practical factors critical to successful collaboration. Specifically, we investigate how varying model reliability and cognitive framing influence human trust, cognitive load, and annotation behavior in HITL systems. We show that model reliability and psychological framing significantly impact annotators' trust, engagement, and consistency, offering insights into optimizing HITL frameworks. Through three experimental scenarios with 29 participants-baseline model reliability (S1), fabricated errors (S2), and cognitive bias introduced by negative framing-we analyzed behavioral and qualitative data (S3). Reliable predictions (S1) yielded high trust and annotation consistency, while unreliable outputs (S2) induced critical evaluations but increased frustration and response variability. Negative framing (S3) revealed how cognitive bias influenced participants to rate the model as relatable and accurate despite misinformation about its reliability. These findings highlight the importance of reliable machine outputs and psychological factors in shaping effective human-machine collaboration. By leveraging the strengths of both human oversight and automated systems, this study establishes a scalable HITL framework for emotion annotation and sets the stage for broader applications in adaptive learning and human-computer interaction. 
",219,10.1109/ACCESS.2024.3515838,2025,,Human-in-the-loop; Engagement recognition; Computer vision,university,,2025_Human-in-the-Loop_Annotation_for_Image-Based_Engagement_Estimation-_Assessing_the_Impact_of_Model_Reliability_on_Annotation_Accuracy.pdf
MindScratch: A Visual Programming Support Tool for Classroom Learning Based on Multimodal Generative AI,data collection; dataset; eda; screen recording; training data,chatgpt; diffusion model; gan; gat; gpt; gpt-3; gpt-3.5; gpt-4; language model; large language model; llm; ppo; stable diffusion; t5,canvas; cohere; github; processing; python; r; unity,Computational Thinking; Generative AI; Mind Mapping; Programming Support Tool,learners; participants; students; teachers,24,rna,cognitive load; eda; erp; imu,qualitative,3,0,2,1,0,0,2,,children,scratch being a prime example,structured courses and instruc,the applicability of these too,,True,False,False,False,False,True,True,0.931,,0.732,,0.716,,0.709,,0.545,,0.866,,0.907,,,True,True,True,True,False,False,True,0.828,True,0.769,True,0.843,True,0.761,True,0.87,True,0.763,True,0.837,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Yunnong Chen; Shuhong Xiao; Yaxuan Song; Zejian Li; Lingyun Sun; Liuqing Chen,"
 Programming has become an essential component of K-12 education and serves as a pathway for developing computational thinking skills. Given the complexity of programming and the advanced skills it requires, previous research has introduced user-friendly tools to support young learners. However, our interviews with six programming educators revealed that current tools often fail to reflect classroom learning objectives, offer flexible, high-quality guidance, and foster student creativity. This highlights the need for more adaptive and reflective tools. Therefore, we introduced MindScratch, a multimodal generative AI (GAI) powered visual programming support tool. MindScratch aims to balance structured classroom activities with free programming creation, supporting students in completing creative programming projects based on teacher-set learning objectives while also providing programming scaffolding. Our user study results indicate that, compared to the baseline, MindScratch more effectively helps students achieve highquality projects aligned with learning objectives. It also enhances students' computational thinking skills and creative thinking. Overall, we believe that GAI-driven educational tools like MindScratch offer students a focused and engaging learning experience. 
",167,10.1145/nnnnnnn.nnnnnnn,2024,,Computational Thinking; Generative AI; Mind Mapping; Programming Support Tool,elementary school; k-12; primary school,china,2024_-_MindScratch-_A_Visual_Programming_Support_Tool_for_Classroom_Learning_Based_on_Multimodal_Generative_AI.pdf
SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors,data collection; dataset; eda; electrodermal activity; eye movement; eye tracking; eye-tracking; gaze data; heart rate; physiological data; raw data; saccade; sensor data; skin conductance,decision tree; deep learning; deep learning model; gat; mobilenet; neural net; neural network; ppo; random forest; support vector machine; svm; transformer; transformer model; vgg16,processing; r,multimodal sensors; personal space; eye-tracking; wristband sensor; machine learning; deep learning,participants; students,,,accelerometer; cognitive load; eda; electrodermal activity; erp; eye movement; fixation; galvanic skin response; heart rate; imu; movement tracking; physiological data; ppg; saccade; sensor data; skin conductance; skin temperature,quantitative,3,1,0,0,1,1,0,,users,adaptive,,as a confederate approached or,,True,True,False,False,False,True,True,0.931,,0.765,,0.714,,0.711,,0.561,,0.882,,0.918,,,False,False,True,True,False,False,False,0.837,True,0.784,True,0.861,True,0.786,True,0.872,True,0.797,True,0.841,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Ko Watanabe; Nico Förster; Shoya Ishimaru,"
 Personal space, also known as peripersonal space, is crucial in human social interaction, influencing comfort, communication, and social stress. Estimating and respecting personal space is essential for enhancing human-computer interaction (HCI) and smart environments. Personal space preferences vary due to individual traits, cultural background, and contextual factors. Advanced multimodal sensing technologies, including eye-tracking and wristband sensors, offer opportunities to develop adaptive systems that dynamically adjust to user comfort levels. Integrating physiological and behavioral data enables a deeper understanding of spatial interactions. This study aims to develop a sensorbased model to estimate comfortable personal space and identify key features influencing spatial preferences. Here we show that multimodal sensors, particularly eye-tracking and physiological wristband data, can effectively predict personal space preferences, with eye-tracking data playing a more significant role. Our experimental study involving controlled human interactions demonstrates, that the Transformer model achieves the highest predictive accuracy (F1 score: 0.87) for estimating personal space. Eye-tracking features, such as gaze point and pupil diameter, emerge as the most significant predictors, while physiological signals from wristband sensors contribute marginally. These findings highlight the potential for AI-driven personalization of social space in adaptive environments. Our results suggest that multimodal sensing can be leveraged to develop intelligent systems that optimize spatial arrangements in workplaces, educational institutions, and public settings. Future work should explore larger datasets, real-world applications, and additional physiological markers to enhance model robustness. 
",228,10.1145/3290605.3300451,2025,,multimodal sensors; personal space; eye-tracking; wristband sensor; machine learning; deep learning,graduate; graduate students; undergrad; undergraduate; university,albania; azerbaijan; brazil; china; germany; india; iran; mali; russia; turkey,2025_SensPS-_Sensing_Personal_Space_Comfortable_Distance_between_Human-Human_Using_Multimodal_Sensors.pdf
Looking Beyond the Hype: Understanding the Effects of AI on Learning,dataset; eda; training data,chatgpt; deep learning; gan; gat; gpt; gpt-4; language model; large language model; llm; neural net; neural network; ppo; transformer; transformers,cohere; grammarly; orange; processing; r; unity,Artificial intelligence; Educational technology; Learning; Effectiveness; Evidence-based design,learners; students; teachers,,rna,eda; erp; imu,qualitative,4,1,3,0,0,1,1,,students,research backgrounds in ai in,ai can be divided into technol,task performance during the su,,True,True,False,False,False,True,True,0.926,,0.776,,0.724,,0.707,,0.573,,0.864,,0.908,,,True,True,False,True,False,False,True,0.839,True,0.809,True,0.862,True,0.782,True,0.862,True,0.803,True,0.863,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Elisabeth Bauer; Samuel Greiff; Arthur C Graesser; Katharina Scheiter; Michael Sailer,"
 Artificial intelligence (AI) holds significant potential for enhancing student learning. This reflection critically examines the promises and limitations of AI for cognitive learning processes and outcomes, drawing on empirical evidence and theoretical insights from research on AI-enhanced education and digital learning technologies. We critically discuss current publication trends in research on AI-enhanced learning and rather than assuming inherent benefits, we emphasize the role of instructional implementation and the need for systematic investigations that build on insights from existing research on the role of technology in instructional effectiveness. Building on this foundation, we introduce the ISAR model, which differentiates four types of AI effects on learning compared to learning conditions without AI, namely inversion, substitution, augmentation, and redefinition. Specifically, AI can substitute existing instructional approaches while maintaining equivalent instructional functionality, augment instruction by providing additional cognitive learning support, or redefine tasks to foster deep learning processes. However, the implementation of AI must avoid potential inversion effects, such as over-reliance leading to reduced cognitive engagement. Additionally, successful AI integration depends on moderating factors, including students' AI literacy and educators' technological and pedagogical skills. Our discussion underscores the need for a systematic and evidence-based approach to AI in education, advocating for rigorous research and informed adoption to maximize its potential while mitigating possible risks. 
",211,10.1007/s10648-025-10020-8,2025,,Artificial intelligence; Educational technology; Learning; Effectiveness; Evidence-based design,higher education; inclusive education; k-12,,2025_-_Looking_Beyond_the_Hype-_Understanding_the_Effects_of_AI_on_Learning.pdf
"Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools",eda; test data,chatgpt; claude; deep learning; gan; gat; gemini; gpt; gpt-3; gpt-3.5; gpt-4; language model; large language model; llm; ppo; transformer; transformer model,aws; excel; github; numbers; python; r; slack; unity; zoom,generative AI; GenAI; large language models; artificial intelligence; pedagogical practices; teaching computing; computing education,learners; participants; respondents; students; teachers,399,mutation; rna,eda; erp; imu,qualitative,3,1,1,2,1,0,3,,teachers,integrating genai into their c,before,each paper according to its pr,,True,False,False,False,False,True,True,0.928,,0.732,,0.708,,0.703,,0.544,,0.86,,0.898,,,True,False,True,True,False,True,False,0.83,True,0.769,True,0.839,True,0.744,False,0.858,True,0.759,True,0.866,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,James Prather; Juho Leinonen; Natalie Kiesler; Jamie Gorson Benario; Sam Lau; Stephen Macneil; Narges Norouzi; Simone Opel; Vee Pettit; Leo Porter; Brent N Reeves; Jaromir Savelka; David H Smith; Sven Strickroth; Daniel Zingaro,"
 Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report * Co-leader 
",173,10.1145/XXXXXXX,2024,,generative AI; GenAI; large language models; artificial intelligence; pedagogical practices; teaching computing; computing education,bachelor's degree; college; graduate; graduate students; higher education; k-12; undergrad; undergraduate; university,australia; canada; finland; france; germany; iceland; ireland; italy; netherlands; new zealand; poland; spain; sweden; switzerland; uk; united kingdom; united states,"2025_-_Beyond_the_Hype-_A_Comprehensive_Review_of_Current_Trends_in_Generative_AI_Research,_Teaching_Practices,_and_Tools.pdf"
Concentration Estimation in Online Video Lecture Using Multimodal Sensors,data collection; gaze data; heart rate; heart rate variability; sensor data; test data; training data,decision tree; ppo; random forest; svm,openface; processing; r,Wearable sensor; multimodal sensing; concentration detection; online learning; machine learning,participants; students,31,,accelerometer; emotional state; gyroscope; heart rate; heart rate variability; imu; sensor data; wearable sensor,quantitative,3,0,0,0,0,0,0,,students,jins meme glasses to measure c,onsite learning,at,,True,False,False,False,False,True,True,0.934,,0.746,,0.713,,0.709,,0.553,,0.883,,0.92,,,False,False,True,True,False,False,False,0.836,True,0.772,True,0.859,True,0.764,True,0.878,True,0.778,True,0.849,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Noriyuki Tanaka; Ko Watanabe; Shoya Ishimaru; Andreas Dengel; Shingo Ata; Manato Fujimoto,"
 Online lecture is one of the technology-wise challenges in the education field. It provides the advantage of encouraging anyone to join from worldwide. However, understanding students' concentration in remote is one of the difficulties. In this paper, we evaluate multimodal sensors for estimating students' concentration levels during online video lectures. We collect multimodal sensor data such as accelerometers, gyroscopes, heart rates, facial orientations, and eye gazes. We conducted experiments with 13 university students in Japan. The results of our study, with an average accuracy rate of 74.4% for user-dependent cross-validation and 66.3% for user-independent cross-validation, have significant implications for understanding and improving student engagement in online learning environments. Most interestingly, we found that facial orientations are significant for user-dependent and eye gazes for user-independent classification. 
 CCS CONCEPTS • Human-centered computing → Ubiquitous and mobile computing; • Applied computing → E-learning; Distance learning; • Hardware → Sensor applications and deployments. 
",149,10.1145/3675094.3677587,,,Wearable sensor; multimodal sensing; concentration detection; online learning; machine learning,university,japan,2024_-_Concentration_estimation_in_online_video_lecture_using_multimodal_sensors.pdf
Pedagogical incorporation of artificial intelligence in K-12 science education: A decadal bibliometric mapping and systematic literature review (2013-2023),dataset; eda; eeg; interaction logs,chatgpt; claude; deep learning; gan; gat; gpt; gru; neural net; neural network; ppo,processing; r,Artificial intelligence; K-12 science education; Systematic review; Bibliometric mapping; Pedagogical strategies,learners; participants; students; subjects; teachers,12,rna,eda; eeg; erp; imu,qualitative,3,0,1,0,0,1,4,,students,interactive simulations and vi,providing a comprehensive over,for eligibility,,True,True,False,False,False,True,True,0.914,,0.795,,0.714,,0.715,,0.605,,0.878,,0.914,,,True,False,True,True,False,False,False,0.837,True,0.793,True,0.868,True,0.773,True,0.869,True,0.795,True,0.844,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,K Kavitha; V P Joshith,"
 Artificial intelligence (AI) technologies continue to revolutionize various sectors, including their incorporation into education, particularly in K-12 science education, which has become evidently significant. This paper presents a bibliometric analysis and systematic review that examines the incorporation of AI technologies in K-12 science education. A total of 20 studies, comprising journal articles and conference proceedings published between 2013 and 2023 and sourced from the Scopus database, were analyzed to identify leading journals, influential papers, and authors, and county-wise contributions. The study reveals that AI technologies, including robotics, chatbots, machine learning, automated scoring -feedback, and neural networks, have demonstrably enhanced learning outcomes, increased student engagement, and facilitated personalized education in science classrooms. Further, the review identifies diverse methodological approaches and pedagogical strategies, including hands-on learning, blended learning models, inquiry-based methods, and feedback-based learning, as practical means of incorporating AI within science classrooms. Moreover, the key findings emphasized the importance of professional development, infrastructure investment, and ethical guidelines to support equitable implementation of AI in science education. This study also advocates future research investigating long-term impacts, ethical considerations, and qualitative insights to fully understand AI's potential in enhancing K-12 science education. 
",189,10.33902/JPR.202429218,2024,,Artificial intelligence; K-12 science education; Systematic review; Bibliometric mapping; Pedagogical strategies,elementary school; grade 7; high school; junior high school; k-12; middle school; online learning; primary school; secondary education; secondary school,australia; china; turkey; uk; united states,2024_-_Pedagogical_incorporation_of_artificial_intelligence_in_K-12_science_education-_A_decadal_bibliometric_mapping_and_systematic_literature_review_(2013-2023)_.pdf
Multimodality of AI for Education: Towards Artificial General Intelligence,benchmark dataset; data collection; data sample; dataset; eda; facial expression; multimodal dataset; training data,autoencoder; bert; chatgpt; cnn; convolutional neural network; deep learning; denoising autoencoder; diffusion model; gan; gat; gemini; generative adversarial network; gpt; gpt-2; gpt-3; gpt-3.5; gpt-4; instructgpt; language model; large language model; llama; llama-2; llm; lstm; neural net; neural network; ppo; random forest; recurrent neural network; reinforcement learning; resnet; rnn; stable diffusion; support vector machine; transformer; transformers; vae; variational autoencoder,aws; cohere; excel; processing; r; unity,Artificial General Intelligence (AGI); Machine Learning; ChatGPT; GPT-4V; Gemini; Multimodality; Education,learners; students; subjects; teachers,1,genome; rna,brain signal; cognitive load; eda; emotional state; erp; imu,qualitative,3,2,2,1,0,0,0,,learners,an exposition of the multimoda,singlemedia learning,by it,,True,True,False,False,False,True,True,0.932,,0.759,,0.715,,0.712,,0.561,,0.868,,0.909,,,False,True,False,False,False,True,True,0.84,True,0.788,True,0.858,True,0.781,True,0.87,True,0.784,True,0.853,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Gyeong-Geon Lee; Lehong Shi; Ehsan Latif; Yizhu Gao; Arne Bewersdorff; Matthew Nyaaba; Shuchen Guo; Zihao Wu; Zhengliang Liu; Hui Wang; Gengchen Mai; Tiaming Liu; Xiaoming Zhai,"
 This paper presents a comprehensive examination of how multimodal artificial intelligence (AI) approaches are paving the way towards the realization of Artificial General Intelligence (AGI) in educational contexts. It scrutinizes the evolution and integration of AI in educational systems, emphasizing the crucial role of multimodality, which encompasses auditory, visual, kinesthetic, and linguistic modes of learning. This research delves deeply into the key facets of AGI, including cognitive frameworks, advanced knowledge representation, adaptive learning mechanisms, strategic planning, sophisticated language processing, and the integration of diverse multimodal data sources. It critically assesses AGI's transformative potential in reshaping educational paradigms, focusing on enhancing teaching and learning effectiveness, filling gaps in existing methodologies, and addressing ethical considerations and responsible usage of AGI in educational 
",120,10.1109/ICCV.2015.287,2023,,Artificial General Intelligence (AGI); Machine Learning; ChatGPT; GPT-4V; Gemini; Multimodality; Education,college; graduate; higher education; k-12; undergrad; undergraduate; university,georgia; mali,2023_-_Multimodality_of_AI_for_Education-_Towards_Artificial_General_Intelligence.pdf
Img2Vocab: Explore Words Tied to Your Life With LLMs and Social Media Images,data collection; eda; eye-tracking; training data,chatgpt; cnn; gat; gemini; gpt; gpt-3; gpt-4; language model; large language model; llama; llm; machine learning model; ml model; ppo; rnn; transformer,firebase; numbers; openai api; processing; python; r,,learners; participants; students; teachers,23,rna,eda; erp; imu,qualitative,2,0,1,0,0,0,2,,learners,prior experience,context and,our first-of-its-kind system d,,True,False,False,False,False,True,True,0.932,,0.73,,0.719,,0.701,,0.545,,0.866,,0.902,,,False,False,False,False,False,False,False,0.837,True,0.774,True,0.842,True,0.764,True,0.867,True,0.761,True,0.863,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Kanta Yamaoka; K O Watanabe; Koic Kise; Andreas Dengel,"
 Psychological studies highlight the importance of combining new knowledge with one's prior experience. Hence personalization for a learner plays a key role for vocabulary acquisition. However, this faces two challenges: probing a learner's experiences in their lives and crafting tailored material for every different individual. With the prevalence of visual social media, such as Instagram, people share their photos from favorite moments, providing rich contexts, and emerging generative AI would create learning material in an effortless fashion. We prototyped an online vocabulary exploration system, which displays a learner's selected photos from their Instagram along with a generated sentence using image recognition and a language model, GPT-3. The system lets a learner find new words that are strongly tied to their daily life with the approximated context. We carried out our within-subject design evaluation of the system with 23 participants with three conditions: contexts grounded with learner's Instagram photos, contexts grounded from general images, and text-only modality. From learners' recall task accuracy, we found that having a context grounded with a learner's social image allowed them to find difficult words to quickly learn than having context generated by someone's image, or text only modality-although this finding is statistically insignificant. The Zipf frequency comparisons revealed that generally having image-based context allowed learners to extract difficult vocabulary than having text-only context. We also discuss quantitative and qualitative results regarding participants' acceptance of the personalization system using their personal photos from social media. Generally, they reported positive impressions for our system such as high engagement. While our system prioritizes user privacy with opt-in data control and secure design, we explore additional ethical considerations. This paves the way for a future where personalized language learning, grounded in real-world experiences and generative AI, benefits learners. INDEX TERMS Context-aware language learning, HCI, large language models, generative AI. 
",300,10.1109/ACCESS.2025.3533076,,,,university,japan; mali,2025_Img2Vocab-_Explore_Words_Tied_to_Your_Life_with_LLMs_and_Social_Media_Images.pdf
Visual Learning: The Power of Visual Aids and Multimedia,,gan; gat; ppo,aws; blackboard; canvas; excel; google classroom; processing; r; unity,visual learning; visual aids; multimedia; learning styles; educational strategies; mind mapping; cognitive processing; visual engagement; personalized learning; interactive learning tools; spatial reasoning. I. Introduction,learners; students; subjects,,rna,cognitive load; erp; imu,quantitative,1,0,0,0,0,1,2,,learners,a predominant visual learning,other learning styles while vi,comprehension,,True,True,False,False,False,True,True,0.934,,0.769,,0.727,,0.712,,0.572,,0.86,,0.911,,,False,False,False,True,False,False,False,0.852,True,0.824,True,0.865,True,0.811,True,0.879,True,0.825,True,0.817,True,,0.7,True,True,False,True,True,True,True,False,False,True,analytic,Moses Alabi,"
 Visual learning is a learning style that emphasizes the use of images, diagrams, charts, and other visual aids to enhance comprehension and retention. Visual learners thrive when information is presented through visually engaging materials, which helps them organize and process complex information more effectively. This learning style is particularly beneficial in subjects that involve spatial reasoning, conceptual relationships, and pattern recognition, as it enables learners to see connections and structures that might be less apparent in text-based or auditory formats. This paper explores the cognitive processes underlying visual learning and the advantages of using visual aids to facilitate knowledge acquisition. Techniques such as mind mapping, infographics, flowcharts, and videos are examined as tools that support memory retention and deepen understanding. The study also considers the role of multimedia in visual learning, analyzing how animations, interactive graphics, and virtual reality applications can enrich the learning experience by making abstract concepts more concrete and engaging. Additionally, this paper discusses the implementation of visual learning strategies in various educational contexts, including science, mathematics, and history, where complex data and processes can be better understood with visual supports. Challenges associated with this learning style, such as limited effectiveness in purely text-based environments, are addressed, along with recommendations for creating inclusive learning environments that integrate visual aids with other learning modalities. By emphasizing the importance of visual aids and multimedia, this research highlights how visual learning can be leveraged to improve educational outcomes and cater to diverse learning preferences. 
",244,10.1080/08923640902854405,2024,,visual learning; visual aids; multimedia; learning styles; educational strategies; mind mapping; cognitive processing; visual engagement; personalized learning; interactive learning tools; spatial reasoning. I. Introduction,high school; middle school,united states,2024_-_Visual_Learning-_The_Power_of_Visual_Aids_and_Multimedia.pdf
AI-Driven Cognitive Modeling: Integrating Eye Tracking and Machine Learning for Personalized User Insights,dataset; eye movement; eye tracking; gaze data; physiological data; pupil dilation; saccade,gat; machine learning model; neural net; neural network; ppo; support vector machine,notion; processing; r; unity,Eye tracking; machine learning; cognitive modeling; personalized insights; user experience; behavioral analytics; adaptive systems,students,,rna,cognitive load; emotional state; erp; eye movement; fixation; physiological data; pupil dilation; saccade,qualitative,1,0,0,1,0,0,0,,users,computational means,compromising trust or security,user engagement and reduced ti,,True,True,False,False,False,True,True,0.923,,0.779,,0.734,,0.725,,0.568,,0.856,,0.903,,,False,False,True,False,False,False,False,0.846,True,0.819,True,0.86,True,0.81,True,0.863,True,0.816,True,0.842,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,,"
 This study explores the integration of eye tracking and machine learning to advance AI-driven cognitive modeling, enabling the development of personalized user insights. By capturing gaze patterns and applying predictive analytics, the research aims to understand user attention, decisionmaking processes, and cognitive load in real time. Machine learning algorithms analyze vast datasets from eye movements to identify unique behavioral patterns, enhancing user profiling and adaptive interface design. This approach fosters more intuitive human-computer interaction, optimizing user experience in sectors such as education, healthcare, and e-commerce. The findings underscore the potential of combining physiological data with AI to drive innovative applications in cognitive science and technology. 
",105,10.13140/RG.2.2.29692.04482,2024,,Eye tracking; machine learning; cognitive modeling; personalized insights; user experience; behavioral analytics; adaptive systems,online learning,mali,2024_-_AI-Driven_Cognitive_Modeling-_Integrating_Eye_Tracking_and_Machine_Learning_for_Personalized_User_Insights.pdf
Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling,data collection; dataset; eda,bert; chatgpt; claude; deep learning; gan; gat; gemini; gpt; language model; large language model; llm; ppo; transformer; transformers,anthropic; cohere; github; huggingface; r,artificial intelligence; education; topic modeling; large language models; multimodal,students; teachers,5000,,eda; erp; imu,qualitative,1,0,1,0,0,0,1,,students,regulatory efforts trying to a,exhaustively testing every com,as follows,,True,True,False,False,False,True,True,0.92,,0.762,,0.701,,0.713,,0.586,,0.876,,0.909,,,True,False,False,False,False,False,False,0.834,True,0.766,True,0.848,True,0.769,True,0.865,True,0.778,True,0.85,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Ville Heilala; Roberto Araya; Raija Hämäläinen,"
 Generative artificial intelligence (GenAI) can reshape education and learning. While large language models (LLMs) like ChatGPT dominate current educational research, multimodal capabilities-such as text-to-speech and text-to-image-are less explored. This study uses topic modeling to map the research landscape of multimodal and generative AI in education. An extensive literature search yielded 4175 articles. Employing a topic modeling approach, latent topics were extracted, resulting in 38 interpretable topics organized into 14 thematic areas. Findings indicate a predominant focus on text-to-text models in educational contexts, with other modalities underexplored, overlooking the broader potential of multimodal approaches. The results suggest a research gap, stressing the importance of more balanced attention across different AI modalities and educational levels. In summary, this research provides an overview of current trends in generative AI for education, underlining opportunities for future exploration of multimodal technologies to fully realize the transformative potential of artificial intelligence in education. 
 CCS Concepts • Applied computing → Education; • Computing methodologies → Artificial intelligence; Information extraction; • General and reference → Surveys and overviews. 
",170,10.1145/3672608.3707764,2025,,artificial intelligence; education; topic modeling; large language models; multimodal,higher education; k-12,,2024_-_Beyond_Text-to-Text-_An_Overview_of_Multimodal_and_Generative_Artificial_Intelligence_for_Education_Using_Topic_Modeling.pdf
The Role of Artificial Intelligence in Computer Science Education: A Systematic Review with a Focus on Database Instruction,data collection; dataset; eda; training data,chatgpt; claude; gan; gat; gemini; gpt; gpt-3; gpt-3.5; gpt-4; language model; large language model; llm; openai gpt; ppo; reinforcement learning; transformer; transformers,github; moodle; processing; python; r; redis; unity,artificial intelligence; generative AI; ChatGPT; computer science education; programming education; database instruction; AI in education; systematic review,learners; participants; students; subjects; teachers,264,rna,cognitive load; eda; erp,qualitative,2,2,0,1,0,0,3,,students,ai now being present in many a,a deeper analysis of its pedag,by examining publication sourc,,True,True,False,False,False,True,True,0.913,,0.777,,0.704,,0.707,,0.593,,0.871,,0.904,,,True,False,True,True,False,False,False,0.832,True,0.786,True,0.856,True,0.773,True,0.863,True,0.793,True,0.843,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Alkmini Gaitantzi; Ioannis Kazanidis,"
 The integration of artificial intelligence (AI) into computer science (CS) education is evolving, yet its specific application in database instruction remains underexplored. This systematic review analyzes 31 empirical studies published between 2020 and 2025, examining how AI applications support teaching and learning in CS, with an emphasis on database education. Following the PRISMA methodology, the review categorizes AI applications according to instructional design models, roles, actions, benefits, and challenges. Findings indicate that AI tools, particularly chatbots, intelligent tutoring systems, and code generators, effectively support personalized instruction, immediate feedback, and interactive problem-solving across CS and database-specific contexts. However, challenges persist, including AI inaccuracies, biases, student dependency in AI, and academic integrity risks. The review also identifies a shift in programming education as AI reshapes software development practices, prompting a need to align curricula with evolving industry expectations. Despite growing attention to AI applications in programming education, database-related research remains limited. This review highlights the necessity for further empirical investigations specifically in database instruction, including more extensive studies addressing AI-driven pedagogical strategies and their long-term impacts. The results suggest that careful integration of AI tools can complement traditional instruction, emphasizing the critical role of human educators in achieving meaningful and effective learning outcomes. 
",201,10.3390/app15073960,2025,,artificial intelligence; generative AI; ChatGPT; computer science education; programming education; database instruction; AI in education; systematic review,college; graduate; graduate students; higher education; k-12; undergrad; undergraduate; undergraduate students; university,mali,2025_-__The_Role_of_Artificial_Intelligence_in_Computer_Science_Education-_A_Systematic_Review_with_a_Focus_on_Database_Instruction_.pdf
Investigating students' cognitive processes in generative AI-assisted digital multimodal composing and traditional writing,data collection; eda; screen recording,chatgpt; convolutional neural network; gan; gat; gpt; gpt-2; gpt-3; gpt-4; language model; large language model; neural net; neural network; ppo; recurrent neural network; transformer,aws; grammarly; processing; quillbot; r; redis; zoom,,participants; students; subjects; teachers,,rna,eda; erp; imu,qualitative,2,0,1,0,2,0,3,,students,a generative ai-driven image s,those visual artists produce,by grammarly,,True,False,False,False,False,True,True,0.928,,0.742,,0.711,,0.69,,0.568,,0.867,,0.898,,,True,True,True,True,False,False,False,0.84,True,0.776,True,0.839,True,0.767,True,0.86,True,0.766,True,0.864,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Meilu Liu; Lawrence Jun Zhang; Christine Biebricher,"
 Recently, generative artificial intelligence (AI)-powered chatbots such as ChatGPT and Bing Chat have garnered increasing attention on a global scale. Previous studies have focused mostly on the influence of generative AI on writing while few researchers have investigated how generative AI can facilitate students' multimodal writing process. To fill in this gap, we explored the generative AI-assisted composing processes of two groups of English as a foreign language (EFL) writers over two weeks in this qualitative study. One group completed a multimodal PowerPoint (PPT) project, and the other group completed a traditional argumentative essay project. Our data consist of students' screen recordings with think-aloud protocols, final multimodal texts, and post-project interviews. Our analysis showed different patterns in text production across the two groups. Students in the PPT group tended to construct more bridge texts and examples to corroborate their sub-claims in the hierarchical order. They also inclined to borrow the summarized search results from the Bing Chat to expand texts for their PPT slides. With regard to image generation for PPT slides, descriptions of AI images from ChatGPT were used as effective prompts to generate AI images from Bing Image Creator. Moreover, students were interested in producing and refining AI images following the recommended prompts by Bing Chat. They also evaluated these AI images from different perspectives. We conclude the study with a discussion on the pedagogical implications and suggestions for further study. 
",233,10.1016/j.compedu.2023.104977,2023,,,graduate; graduate students; undergrad; undergraduate; undergraduate students; university,new zealand,2023_-_Investigating_students’_cognitive_processes_in_generative_AI-assisted_digital_multimodal_composing_and_traditional_writing.pdf
Metacognition-EnGauge: Real-time Augmentation of Self-and-Group Engagement Levels Understanding by Gauge Interface in Online Meetings,,gat; mobilenet; ppo,r; unity,,participants; students; teachers,18,rna,affective computing,quantitative,2,0,0,1,0,0,0,,participants,the covid-,fee provided that copies are n,,,True,False,False,False,False,True,True,0.934,,0.736,,0.716,,0.725,,0.548,,0.876,,0.918,,,True,False,True,False,False,False,False,0.833,True,0.761,True,0.843,True,0.737,False,0.872,True,0.766,True,0.843,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,K O Watanabe; Rptu Kaiserslautern-Landau; Dfki Gmbh; Andreas Germany; Rptu Dengel; Dfki Kaiserslautern-Landau; Gmbh; Germany,,0,10.1145/3652920.3653054,,,,,australia,2024_-_Metacognition-engauge-_Real-time_augmentation_of_self-and-group_engagement_levels_understanding_by_gauge_interface_in_online_meetings.pdf
Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy,data collection; dataset; emotion detection; eye-tracking; facial expression; physiological data,cnn; convolutional neural network; deep learning; gat; lstm; mobilenet; neural net; neural network; ppo; recurrent neural network; reinforcement learning; rnn; transformer; transformers,excel; processing; r,Human-in-the-loop; Engagement recognition; Computer vision,participants; students,112,rna,blink rate; cognitive load; emotional state; erp; imu; physiological data,qualitative,1,3,1,0,1,0,2,,students,data such as facial expression,,the accuracy of emotion recogn,,True,True,False,False,False,True,True,0.928,,0.779,,0.724,,0.747,,0.569,,0.878,,0.923,,,True,False,True,False,False,False,True,0.843,True,0.791,True,0.873,True,0.78,True,0.872,True,0.79,True,0.85,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Sahana Yadnakudige Subramanya; Ko Watanabe,"
 Human-in-the-loop (HITL) frameworks are increasingly recognized for their potential to improve annotation accuracy in emotion estimation systems by combining machine predictions with human expertise. This study focuses on integrating a high-performing image-based emotion model into a HITL annotation framework to evaluate humanmachine interaction's collaborative potential and uncover the psychological and practical factors critical to successful collaboration. Specifically, we investigate how varying model reliability and cognitive framing influence human trust, cognitive load, and annotation behavior in HITL systems. We show that model reliability and psychological framing significantly impact annotators' trust, engagement, and consistency, offering insights into optimizing HITL frameworks. Through three experimental scenarios with 29 participants-baseline model reliability (S1), fabricated errors (S2), and cognitive bias introduced by negative framing-we analyzed behavioral and qualitative data (S3). Reliable predictions (S1) yielded high trust and annotation consistency, while unreliable outputs (S2) induced critical evaluations but increased frustration and response variability. Negative framing (S3) revealed how cognitive bias influenced participants to rate the model as relatable and accurate despite misinformation about its reliability. These findings highlight the importance of reliable machine outputs and psychological factors in shaping effective human-machine collaboration. By leveraging the strengths of both human oversight and automated systems, this study establishes a scalable HITL framework for emotion annotation and sets the stage for broader applications in adaptive learning and human-computer interaction. 
",219,10.1109/ACCESS.2024.3515838,2025,,Human-in-the-loop; Engagement recognition; Computer vision,university,,2025_-_Human-in-the-Loop_Annotation_for_Image-Based_Engag.pdf
Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education,dataset; eda; raw data; sensor data,chatgpt; deep learning; falcon; gan; gat; gemini; gpt; gpt-4; language model; large language model; llama; llm; ppo; reinforcement learning; vicuna,aws; cohere; pandas; processing; r; unity,Artificial Intelligence; Large Language Models (LLMs); ChatGPT; Multimodal Learning; Cognitive Theory of Multimedia Learning; Science Education,learners; students; teachers,,rna,cognitive load; eda; erp; sensor data,quantitative,1,2,1,0,0,0,0,,students,different modalities,non-verbal,,,True,True,False,False,False,True,True,0.937,,0.758,,0.724,,0.712,,0.569,,0.865,,0.911,,,True,True,False,False,False,False,True,0.848,True,0.794,True,0.859,True,0.791,True,0.872,True,0.789,True,0.851,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Arne Bewersdorff; Christian Hartmann; Marie Hornberger; Kathrin Sessler; Maria Bannert; Enkelejda Kasneci; Gjergji Kasneci; Xiaoming Zhai; Claudia Nerdel,"
 The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. This paper derives a theoretical framework for integrating MLLMs into Multimodal Learning. This framework serves to explore the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs range from content creation to tailored support for learning, fostering engagement in scientific practices, and providing assessments and feedback. These applications are not limited to text-based and uni-modal formats but can be multimodal, thus increasing personalization, accessibility, and potential learning effectiveness. Despite the many opportunities, challenges such as data protection and ethical considerations become salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educators' roles, ensuring an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs for educators and to extend the discourse beyond science education to other disciplines. Through developing a theoretical framework for the integration of MLLMs into Multimodal Learning and exploring the associated potentials, challenges, and future implications, this paper contributes to a preliminary examination of the transformative role of MLLMs in science education and beyond. 
",260,,2024,,Artificial Intelligence; Large Language Models (LLMs); ChatGPT; Multimodal Learning; Cognitive Theory of Multimedia Learning; Science Education,grade 1; grade 12; grade 5,germany; uk,2024_-_Taking_the_Next_Step_with_Generative_Artificial_Intelligence-_The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education.pdf
Generative AI and multimodal data for educational feedback: Insights from embodied math learning,data collection; eda; eye movement; eye tracking; eye-tracking; gaze data; pupil dilation; saccade; system logs,gan; gat; gpt; gpt-4; language model; large language model; llm; ppo,excel; numbers; processing; r; unity,,learners; participants; students; subjects; teachers,34,rna,cognitive load; eda; erp; eye movement; fixation; imu; mental effort; pupil dilation; pupil size; saccade,qualitative,2,1,0,1,3,0,2,,subjects,the environment,human instructor feedback in t,educational outcomes,,True,False,False,False,False,True,True,0.94,,0.746,,0.726,,0.721,,0.55,,0.876,,0.923,,,True,True,True,True,False,False,False,0.84,True,0.78,True,0.858,True,0.771,True,0.877,True,0.781,True,0.844,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Giulia Cosentino; Jacqueline Anton; Kshitij Sharma; | Mirko Gelsomini; Michail Giannakos; | Dor Abrahamson,"
 This study explores the role of generative AI (GenAI) in providing formative feedback in children's digital learning experiences, specifically in the context of mathematics education. Using multimodal data, the research compares AI-generated feedback with feedback from human instructors, focusing on its impact on children's learning outcomes. Children engaged with a digital body-scale number line to learn addition and subtraction of positive and negative integers through embodied interaction. The study followed a between-group design, with one group receiving feedback from a human instructor and the other from GenAI. Eye-tracking data and system logs were used to evaluate student's information processing behaviour and cognitive load. The results revealed that while task-based performance did not differ significantly between conditions, the GenAI feedback condition demonstrated lower cognitive load and students show different visual information processing strategies among the two conditions. The findings provide empirical support for the potential of GenAI to complement traditional teaching by providing structured and adaptive feedback that supports efficient learning. The study underscores the importance of hybrid intelligence approaches that integrate human and AI feedback to enhance learning through synergistic feedback. This research offers valuable insights for educators, developers and researchers aiming to design hybrid AI-human educational environments that promote effective learning outcomes. 
",203,10.1111/bjet.13587,,,,university,mali; norway; uk,2025_-_Generative_AI_and_multimodal_data_for_educational_feedback-_Insights_from_embodied_math_learning.pdf
AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking,data set; dataset,bert; gan; gat; ppo; random forest,cohere; excel; grammarly; notion; processing; r; unity,AI; artificial intelligence; critical thinking; cognitive offloading; AI tools; technology and education; cognitive development; Halpern Critical Thinking Assessment; digital dependence; AI trust,participants; students,669,illumina; mutation; rna,cognitive load; erp; imu,qualitative,1,2,2,2,1,0,3,,users,external tools to reduce the c,questioning or evaluating them,critical thinking skills,,True,True,False,False,False,True,True,0.936,,0.774,,0.726,,0.73,,0.574,,0.882,,0.929,,,True,True,True,True,False,False,True,0.841,True,0.786,True,0.875,True,0.769,True,0.881,True,0.783,True,0.859,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Michael Gerlich,"
 The proliferation of artificial intelligence (AI) tools has transformed numerous aspects of daily life, yet its impact on critical thinking remains underexplored. This study investigates the relationship between AI tool usage and critical thinking skills, focusing on cognitive offloading as a mediating factor. Utilising a mixed-method approach, we conducted surveys and in-depth interviews with 666 participants across diverse age groups and educational backgrounds. Quantitative data were analysed using ANOVA and correlation analysis, while qualitative insights were obtained through thematic analysis of interview transcripts. The findings revealed a significant negative correlation between frequent AI tool usage and critical thinking abilities, mediated by increased cognitive offloading. Younger participants exhibited higher dependence on AI tools and lower critical thinking scores compared to older participants. Furthermore, higher educational attainment was associated with better critical thinking skills, regardless of AI usage. These results highlight the potential cognitive costs of AI tool reliance, emphasising the need for educational strategies that promote critical engagement with AI technologies. This study contributes to the growing discourse on AI's cognitive implications, offering practical recommendations for mitigating its adverse effects on critical thinking. The findings underscore the importance of fostering critical thinking in an AI-driven world, making this research essential reading for educators, policymakers, and technologists. 
",205,10.3390/soc15010006,2025,,AI; artificial intelligence; critical thinking; cognitive offloading; AI tools; technology and education; cognitive development; Halpern Critical Thinking Assessment; digital dependence; AI trust,bachelor's degree; college; doctoral; doctoral level; graduate; high school; higher education; master's degree; secondary education,uk; united kingdom,2025_-__AI_Tools_in_Society-_Impacts_on_Cognitive_Offloading_and_the_Future_of_Critical_Thinking_.pdf
Education and Information Technologies,data collection; dataset; eda,gan; gat; llm; ppo,cohere; excel; numbers; r; unity,Cognitive Diagnostic Modeling; Programming Education; Information Technology; Computer Science; Educational Assessment,learners; participants; students,308,illumina; rna,eda; erp; imu,quantitative,0,2,0,0,0,0,0,,students,the evolving needs of learners,strong skills in these areas,under similar conditions,,True,False,False,False,False,True,True,0.904,,0.732,,0.683,,0.709,,0.549,,0.865,,0.9,,,False,True,False,True,False,False,False,0.808,True,0.742,False,0.838,True,0.746,False,0.854,True,0.76,True,0.813,True,,0.6,True,True,False,True,False,True,True,False,False,True,analytic,Manuel B Garcia,"
 The global shortage of skilled programmers remains a persistent challenge. High dropout rates in introductory programming courses pose a significant obstacle to graduation. Previous studies highlighted learning difficulties in programming students, but their specific weaknesses remained unclear. This gap exists due to the predominant focus on the overall academic performance evaluation. To address this gap, this study employed cognitive diagnostic modeling (CDM) to profile the skill mastery of programming students. An empirical analysis was conducted to select the most appropriate model for the data, and the linear logistic model (LLM) was determined to be the best fit. Final examination results from 308 information technology (IT) and 279 computer science (CS) students were analyzed using the LLM. Unfortunately, findings revealed that programming students exhibited proficiency primarily in code tracing and language proficiency but displayed deficits in theoretical understanding, logical reasoning, and algorithmic thinking. From a practical standpoint, this deficiency in fundamental skills sheds light on the factors contributing to academic failures and potentially eventual dropout in programming education. When comparing the student population by academic program, CS students demonstrated superior mastery compared to their IT counterparts, although both groups exhibited a lack of mastery in code tracing. These deviations underscore the pressing need for tailored educational strategies that address the unique strengths and weaknesses of each student group. Overall, this study offers valuable insights into programming education literature and contributes to the expanding application of CDM in educational research. 
",238,10.1007/s10639-024-13039-6,2024,,Cognitive Diagnostic Modeling; Programming Education; Information Technology; Computer Science; Educational Assessment,college; early childhood; graduate; higher education; middle school; undergrad; undergraduate; university,canada; china; germany; norway; philippines; singapore; switzerland; uk,2024_-_Profiling_the_Skill_Mastery_of_Introductory_Programming_Students-_A_Cognitive_Diagnostic_Modeling_Approach.pdf
GenAIReading: Augmenting Human Cognition with Interactive Digital Textbooks Using Large Language Models and Image Generation Models,data collection; dataset; eye movement; eye-tracking; saccade,chatgpt; gan; gat; gpt; gpt-3; language model; large language model; llm; ppo; reinforcement learning; transformer; transformers,cohere; excel; netlify; processing; r; unity,large language models; generative models; eye-tracking; text-toimage; prompt engineering,learners; participants; students; subjects,24,rna,eye movement; fixation; imu; neuroimaging; saccade,qualitative,3,0,1,0,1,0,0,,learners,enchanted forests and over ric,the consistently high performa,post-reading test scores by,,True,False,False,False,False,True,True,0.938,,0.744,,0.723,,0.716,,0.577,,0.882,,0.922,,,False,False,True,True,False,False,True,0.848,True,0.773,True,0.857,True,0.782,True,0.879,True,0.774,True,0.843,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Ryugo Morita; Ko Watanabe; Jinjia Zhou; Andreas Dengel; Shoya Ishimaru,"
 Accompanying him were two unlikely friends, Mira, a cautious but clever fox, and Tiko, a cheerful tortoise with a love for stories. 
 Style Encoder Their journey led them through enchanted forests and over rickety bridges, where every step brought new challenges and strengthened their bond. 
 Style Encoder Known for his boundless energy and curiosity, Jasper was the fastest animal in the forest. Accompanying him were two unlikely friends, Mira, a cautious but clever fox, and Tiko, a cheerful tortoise with a love for stories. Their journey led them through enchanted forests and over rickety bridges, where every step brought new challenges and strengthened their bond. They navigated through the dense underbrush, solved riddles whispered by ancient trees, and even crossed paths with a mischievous band of monkeys. Through each obstacle, the trio learned to rely on each other's strengths: Jasper's speed, Mira's cunning, and Tiko's wisdom. ・ ・ 
 Diffusion model Diffusion model 
 ・ ・ Known for his boundless energy and curiosity, Jasper was the fastest animal in the forest. Accompanying him were two unlikely friends, Mira, a cautious but clever fox, and Tiko, a cheerful tortoise with a love for stories. Accompanying him were two unlikely friends, Mira, a cautious but clever fox, and Tiko, a cheerful tortoise with a love for stories. 
",213,10.1145/1358628.1358796,2025,,large language models; generative models; eye-tracking; text-toimage; prompt engineering,university,germany,2024_-_GenAIReading-_Augmenting_Human_Cognition_with_Interactive_Digital_Textbooks_Using_Large_Language_Models_and_Image_Generation_Models.pdf
Doktor der Technischen Wissenschaften in the Doctoral Program,accelerometer data; benchmark dataset; data collection; data sample; data set; dataset; emg; eye-tracking; open dataset; raw data; sensor data; sensor reading; test data; training data,autoencoder; cnn; convolutional net; convolutional neural network; decision tree; deep learning; deep learning model; encoder-decoder; ensemble model; gan; gat; lstm; machine learning model; neural net; neural network; ppo; random forest; recurrent neural network; rnn; svm,aws; cohere; intel realsense; keras; numbers; numpy; orange; pandas; processing; python; r; tensorflow; torch; unity,Atomic action; Primitive Task; Task Various; Other Terminology Manufacturing; Robotics; Construction,participants,,rna,acceleration signal; accelerometer; cognitive load; emg; erp; gyroscope; imu; inertial measurement unit; mental effort; movement sensor; ppg; sensor data; sensor reading; wearable sensor,qualitative,3,1,1,1,0,0,3,,users,data from different sensors,the best of humans or ai alone,safety,,True,False,False,False,False,True,True,0.944,,0.739,,0.708,,0.718,,0.537,,0.879,,0.922,,,True,True,True,True,False,True,False,0.835,True,0.766,True,0.852,True,0.773,True,0.877,True,0.782,True,0.836,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Georgios Sopidis; Alois Ferscha; Paul Lukowicz; Technische Wissenschaften,"
 Activity recognition combined with artificial intelligence is a vital area of research, ranging across diverse domains, from sports and healthcare to smart homes. In the industrial domain, and the manual assembly lines, the emphasis shifts to human-machine interaction and thus to human activity recognition (HAR) within complex operational environments. Developing models and methods that can reliably and efficiently identify repetitive human activities, traditionally just categorized as either simple or complex activities, remains a key challenge in the field. Limitations of the existing methods and approaches include their inability to consider the contextual complexities associated with the performed activities. To address these limitations, this thesis introduces the concept of cognitive augmentation. This approach integrates human activity recognition with advanced AI approaches and feedback mechanisms, that aim to i) enhance awareness and knowledge of the performed activities and tasks ii) optimize workflows, and iii) support worker decision-making. Creating different levels of activity abstractions allows for a more nuanced comprehension of activities and describes the underlying characteristics and patterns. This work proposes a hierarchical taxonomy of activities, categorized into atomic, micro, meso, macro, and mega levels, as a framework for understanding and analyzing industrial workflows. The approach is derived from real world observations of industrial assembly processes and reflects the task composition implemented in realistic operations that align with existing literature. Additionally, it presents a guidance system for sensing in manufacturing to apply artificial intelligence (AI) through the outlined abstraction levels in various processes. Each level of abstraction introduces distinct requirements in sensing, data processing, modeling, and feedback, making the taxonomy a practical starting tool for the development of AI-based HAR systems. ii The implementation of these concepts is demonstrated through real-world prototypes, including a smartwatch for activity monitoring, a smart helmet for cognitive and safety assistance, and depth imaging for macro-level activity recognition. These systems bridge the gap between theoretical models and practical applications, and utilize multi-modal sensor data, such as IMUs and depth cameras, to classify and quantify activities, detect anomalies, and provide real-time feedback to workers. The augmentation of human cognitive abilities with technologies such as AI, aims to guide and optimize industrial assembly, particularly in uncontrolled non-laboratory environments, by i) shaping workflows to enable structured data analysis and ii) highlighting correlations across various levels throughout the assembly progression. The expected impact includes improving task accuracy, reducing human errors, assisting worker training, and enhancing the quality control of final products in complex industrial settings. iii Table  2 .1: This table presents an overview of the existing literature in the domain of human activity recognition, presenting a quantitative distribution of papers across different abstraction levels and domains. The dominance of publications at the simple/complex level across various domains suggests a significant focus on understanding activities in this distinction. On the other hand, the comparatively small number of publications in some areas, such as group activities, suggests possible topics for more investigation and study. Furthermore, the existence of publications at various levels of abstraction highlights the complexity of human activity recognition research and emphasizes the necessity for sophisticated methods of activity analysis and classification. 
",512,10.1038/s41562-024-02024-1,,,Atomic action; Primitive Task; Task Various; Other Terminology Manufacturing; Robotics; Construction,,guinea; iran; mali,2025_Cognitive_Augmentation_for_Manual_Assembly.pdf
Gaze-Based Prediction of Students' Math Difficulties -A Time Dynamic Machine Learning Approach to Enable Early Individual Assistance,data collection; data set; dataset; eye movement; eye tracking; eye-tracking; gaze data; saccade; test data,decision tree; gan; gat; knn; ppo; random forest; support vector machine; svm,processing; python; r; unity,Intelligent tutoring systems; Gaze-based adaptation; Learning difficulty detection,learners; participants; students; subjects,143,rna,cognitive load; erp; eye movement; fixation; imu; saccade,qualitative,2,2,0,0,0,0,2,,students,the aim of recognizing content,previous work,from the gaze data,,True,False,False,False,False,True,True,0.937,,0.711,,0.697,,0.71,,0.522,,0.875,,0.914,,,True,True,True,True,False,False,False,0.827,True,0.748,False,0.841,True,0.747,False,0.863,True,0.747,False,0.843,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Kathrin Kennel; Shoya Ishimaru; Stefan Küchemann; Steffen Steinert; Jochen Kuhn; Stefan Ruzika,"
 Graphical differentiation substantially promotes the understanding of basic concepts of calculus. At the same time, such tasks are challenging for many students. To be able to support students in complex tasks during the solution process, it is important to recognise if students are having difficulties and, if so, to identify precisely what the difficulty is. However, previous research was only able to identify correct and incorrect solution processes but not the specific difficulties of students. In our study, the eye tracking data of 143 students reveal how students' math tasks in context of graphically differentiation can be predicted. Retrospective-think-aloud (RTA) protocols were used to identify students' difficulties and three machine learning algorithms, k-nearest neighbours (KNN), Random Forest and support vector machine (SVM), provide an accurate prediction for this multiclass problem. The prediction results improve with increasing processing time and achieve already good values long before the solution process of the tasks is completed. Our results show that certain student difficulties can be detected very early during the task solution process. Although this approach has been demonstrated for a sub-area of calculus, it is transferable to other fields of the STEM domain and therefore has much wider scope. 
",197,10.1007/s40593-024-00447-5,,,Intelligent tutoring systems; Gaze-based adaptation; Learning difficulty detection,high school; senior high school,germany; uk,2024_Gaze-Based_Prediction_of_Students’_Math_Difficulties-A_Time_Dynamic_Machine_Learning_Approach_to_Enable_Early_Individual_Assistance.pdf
Eye Movement in a Controlled Dialogue Setting,data collection; dataset; eye movement; eye-tracking; gaze data; gaze position; raw data; saccade,autoencoder; deep learning; gat; lstm; neural net; neural network; ppo; variational autoencoder,github; orange; r; unity,CCS CONCEPTS; Computing methodologies → Activity Recognition; Animation Eye Movement; Gaze Synthesis; Data Collection; Animated Avatars,participants; teachers,19,,erp; eye movement; fixation; imu; saccade,quantitative,0,1,0,0,0,0,0,,teachers,autistic children,interruption,,,True,False,False,False,False,True,True,0.93,,0.711,,0.705,,0.687,,0.518,,0.865,,0.903,,,False,False,False,False,False,False,False,0.823,True,0.752,True,0.83,True,0.741,False,0.851,True,0.752,True,0.862,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,David Dembinsky; Ko Watanabe,"
 Designing realistic eye movements for animated avatars poses a challenge, as gaze behavior is predominantly unconscious. Accurately modulating those movements is crucial to avoid the Uncanny Valley. The human gaze exhibits different characteristics in conversations, depending on speaking or listening. Albeit these distinctions are known, data for synthesizing eye movement models suitable for avatars is scarce. This research introduces a novel dataset involving human gaze behavior during remote screen conversations. The data are collected from 19 participants, offering 4 hours of gaze data labeled as Speaking and Listening. Our data analysis substantiates prior knowledge of gaze behavior while providing new insights through higher precision. Furthermore, we demonstrate the dataset's suitability for machine learning algorithms by training a classifier, achieving 88.1% binary classification accuracy. 
",123,10.1145/3649902.3653337,,,CCS CONCEPTS; Computing methodologies → Activity Recognition; Animation Eye Movement; Gaze Synthesis; Data Collection; Animated Avatars,university,india; mali; uk,2024_-_Eye_movement_in_a_controlled_dialogue_setting.pdf
Integrative Analysis of Multimodal Interaction Data: Predicting Communication Dynamics and Willingness to Communicate (WtC) in Human-Agent Interaction,biometric data; data collection; dataset; eda; eye movement; eye tracking; eye-tracking; facial emotion; facial expression; heart rate; interaction logs; physiological data; raw data; saccade,gat; neural net; neural network; ppo; random forest; support vector machine; svm,cohere; openface; processing; r,Human-Agent Interaction; Conversational AI; Biometric Indicators; Machine Learning; and Communication Dynamics,learners; participants,,illumina,biometric data; eda; emotional state; erp; eye movement; fixation; heart rate; imu; physiological data; saccade,qualitative,1,2,0,0,1,0,2,,learners,a second language,,through task completion time,,True,True,False,False,False,True,True,0.93,,0.786,,0.729,,0.734,,0.592,,0.877,,0.921,,,True,False,True,True,False,False,False,0.853,True,0.808,True,0.87,True,0.799,True,0.879,True,0.808,True,0.839,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Aboulhassane Cisse; Kazuhisa Seta; Yuki Hayashi,"
 This research delves into the intricate relationship between physiological and behavioral indicators and the Willingness to Communicate (WtC) in the context of humanagent interactions. Specifically, it examines how heart rate, eye movement, facial expressions, and conversational dynamics influence individuals' engagement and willingness to engage in dialogue with agents. Set to take place in March 2024, the study employs a combination of ANCOVA and SVM machine learning techniques to analyze multimodal interaction data collected from participants engaging with conversational Agent. The aim is to identify patterns and correlations that can predict and subsequently enhance WtC, thereby improving the design and effectiveness of conversational agents. This research stands at the intersection of emotional intelligence, communication studies, and AI technology, offering a novel perspective on enhancing human-agent communication. Through its integrative approach, it seeks to contribute to the development of AI agents that can better understand and respond to human emotional and communicational cues, paving the way for more natural and meaningful digital interactions. 
",161,10.1007/s40593-018-0171-6,,,Human-Agent Interaction; Conversational AI; Biometric Indicators; Machine Learning; and Communication Dynamics,,jordan; mali,2024_Aboul_Hassane_CISSE_-_Doctoral_Consortium.pdf
Adaptive Feedback in Learning Environments: A Multimodal Approach to Enhancing Feedback Sensitivity and Learner Engagement,biometric data; data collection; eye-tracking; facial expression; heart rate; heart rate variability; physiological data; saccade,gat; ppo,openface; r; redis,Adaptive learning; multimodal feedback; learner engagement; emotion recognition; personalized feedback Companion Proceedings 15th International Conference on Learning Analytics & Knowledge (LAK25); AboulHassane C. Companion Proceedings 15th International Conference on Learning Analytics & Knowledge (LAK25); AboulHassane C,learners; participants; students,9,rna,affective computing; attention level; biometric data; bpm; cognitive load; emotional state; erp; fixation; heart rate; heart rate variability; hrv; imu; physiological data; saccade; stress level,qualitative,2,0,0,2,0,0,2,,learners,credit is permitted,fee provided that copies are n,social interaction skills,,True,True,False,False,False,True,True,0.931,,0.758,,0.73,,0.745,,0.558,,0.869,,0.919,,,True,False,True,True,False,False,False,0.84,True,0.796,True,0.87,True,0.778,True,0.869,True,0.788,True,0.837,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,,"
 This research explores the application of multimodal data, including eye-tracking, heart rate variability, and emotion recognition, to deliver real-time adaptive feedback in learning environments. Specifically, the study investigates how this feedback influences learner engagement, task performance, and persistence during English language conversations with a conversational agent in a simulated restaurant scenario. By integrating Affective Backchannels (AB), Conversational Strategies (CS), and their combination (AB+CS), the system provides personalized feedback tailored to both emotional and cognitive states. Preliminary results from 9 participants reveal that real-time feedback effectively reduces frustration-evidenced by lower heart rates and more positive emotional expressions while significantly improving task accuracy and Willingness to Communicate (WtC). This research contributes to learning analytics and adaptive learning technologies by demonstrating how multimodal data can enhance cognitive and emotional learning outcomes. Future work will focus on expanding the dataset, refining individual physiological baselines, and exploring scalability across diverse educational settings, including more emotionally complex scenarios. 
",152,10.1007/s40593-018-0171-6,,,Adaptive learning; multimodal feedback; learner engagement; emotion recognition; personalized feedback Companion Proceedings 15th International Conference on Learning Analytics & Knowledge (LAK25); AboulHassane C. Companion Proceedings 15th International Conference on Learning Analytics & Knowledge (LAK25); AboulHassane C,university,japan,2025_LAK25_DSC___Camera_Ready___Adaptive_Feedback_in_Learning_Environments__A_Multimodal_Approach_to_Enhancing_Feedback_Sensitivity_and_Learner_Engagement-2.pdf
"AI and peer reviews in higher education: students' multimodal views on benefits, differences and limitations",data collection; eda; facial expression,chatgpt; gan; gat; gpt; gpt-3; language model; large language model; llm; ppo,cohere; excel; processing; r; unity,Generative AI; AI feedback; peer reviews; higher education,learners; participants; students; teachers,15,rna,eda; erp; imu,qualitative,3,1,1,0,0,0,2,,teachers,the potential for scalability,peer feedback,and the overall objective to b,,True,False,False,False,False,True,True,0.934,,0.733,,0.717,,0.705,,0.546,,0.87,,0.911,,,True,False,True,False,False,False,False,0.841,True,0.768,True,0.856,True,0.752,True,0.866,True,0.758,True,0.869,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Gabriela C Zapata; Bill Cope; Mary Kalantzis; Anastasia Olga; Olnancy Tzirides; Akash Kumar Saini; Duane Searsmith; Jennifer Whiting; Nikoleta Polyxeni Kastania; Vania Castro; Theodora Kourkoulou; John W Jones; Rodrigo Abrantes Da Silva; Nikoleta Polyxeni Kastania,"
 Since the launch of ChatGPT in November 2022, educational researchers and practitioners have sought to understand the ways in which these new generative AI technologies might influence education. This article describes one such effort. The focus of the investigation was chatbots responding from large language models to the review of open-ended student work. Specifically, the authors examined university students' multimodal views of the benefits and limitations of AI reviews as compared to human feedback. The participants were postgraduate students in a public American university. The students' opinions of their experiences with both types of reviews were expressed linguistically, visually and gesturally, and they were submitted to discursive and socio-semiotic analyses. The results revealed a preference for human reviews. Nevertheless, the participants also identified several benefits for AI feedback, as well as ways in which it had complemented human reviews, overwhelmingly welcoming its addition as part of their educational experience. 
",149,10.1080/1475939X.2025.2480807,,,Generative AI; AI feedback; peer reviews; higher education,college; graduate; graduate students; high school; higher education; online learning; postgraduate; university,japan; united states,"2024_-_AI_and_peer_reviews_in_higher_education-_students’_multimodal_views_on_benefits,_differences_and_limitations.pdf"
Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning,,chatgpt; deep learning; gpt; language model; machine learning model; ppo,processing; r,Generative AI; Educational Technology; ChatGPT; Google Bard; Natural Language Processing,students; teachers,,,erp,unknown,1,0,0,0,0,0,0,,students,the rapid advancement of artif,chatgpt,,,True,True,False,False,False,True,True,0.935,,0.776,,0.727,,0.727,,0.587,,0.873,,0.915,,,False,False,False,True,False,False,False,0.858,True,0.796,True,0.869,True,0.812,True,0.884,True,0.795,True,0.843,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Johnny Chan,"
 This research explores the opportunities of Generative AI (GenAI) in the realm of higher education through the design and development of a multimodal chatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced text-based interactions and Google Bard for advanced image analysis and diagram-to-code conversions, we showcase the potential of GenAI in addressing a broad spectrum of educational queries. Additionally, the chatbot presents a file-based analyser designed for educators, offering deep insights into student feedback via sentiment and emotion analysis, and summarising course evaluations with key metrics. These combinations highlight the crucial role of multimodal conversational AI in enhancing teaching and learning processes, promising significant advancements in educational adaptability, engagement, and feedback analysis. By demonstrating a practical web application, this research underlines the imperative for integrating GenAI technologies to foster more dynamic and responsive educational environments, ultimately contributing to improved educational outcomes and pedagogical strategies. 
",146,,,,Generative AI; Educational Technology; ChatGPT; Google Bard; Natural Language Processing,higher education,,2025_-_Enhancing_Higher_Education_with_Generative_AI-_A_Multimodal_Approach_for_Personalised_Learning.pdf
TrackThinkDashboard: Understanding Student Self-Regulated Learning in Programming Study,data collection; dataset; eye-tracking; physiological data; raw data; sensor data,gan; gat; ppo; random forest,canvas; github; processing; r; unity,,learners; participants; students; teachers,,,physiological data; sensor data,qualitative,2,1,1,2,0,1,1,,students,student web browse programming,needing programming skills,,,True,True,False,False,False,True,True,0.918,,0.754,,0.708,,0.698,,0.571,,0.865,,0.894,,,False,False,False,False,False,False,True,0.835,True,0.785,True,0.833,True,0.784,True,0.854,True,0.778,True,0.856,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Ko Watanabe; Yuki Matsuda; Yugo Nakamura; Yutaka Arakawa; Shoya Ishimaru,"
 In programming education, fostering self-regulated learning (SRL) skills is essential for both students and teachers. This paper introduces Track-ThinkDashboard, an application designed to visualize the learning workflow by combining web browsing and programming logs in one unified view. The system aims to (1) help students monitor and reflect on their problem-solving processes, identify knowledge gaps, and cultivate effective SRL strategies, and (2) enable teachers to identify at-risk learners more effectively and provide targeted, data-driven guidance. We conducted a study with 33 participants (32 male, one female) from Japanese universities-some with prior programming instruction and some without-to explore differences in web browsing and coding patterns. The dashboards revealed multiple learning approaches (e.g., try-and-error, try-and-search, and more) and highlighted how domain knowledge influenced overall activity flow. We discuss how this visualization can be used continuously or in one-off experiments, the privacy considerations involved, and opportunities for expanding data sources for richer behavioral insights. 
",151,10.1109/ABC61795.2024.10651851,2025,,,university,japan; united states,2025-TrackThinkDashboard-Understanding-Student-Self-Regulated-Learning-in-Programming-Study.pdf
A review of assessment for learning with artificial intelligence,data collection; data set; dataset; eda; training data,chatgpt; deep learning; gan; gat; gpt; neural net; neural network; ppo; svm; vae,notion; orange; processing; r,,learners; participants; students; teachers,28,rna,eda; erp; imu,qualitative,1,1,1,1,0,0,3,,learners,assessment for learning is div,a technological,through communication and the,,True,True,False,False,False,True,True,0.938,,0.768,,0.724,,0.719,,0.574,,0.872,,0.919,,,True,False,False,True,False,False,False,0.848,True,0.798,True,0.876,True,0.774,True,0.882,True,0.784,True,0.856,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Bahar Memarian; Tenzin Doleck,"
 The reformed Assessment For Learning (AFL) practices the design of activities and evaluation and feedback processes that improve student learning. While Artificial Intelligence (AI) has blossomed as a field in education, less work has been done to examine the studies and challenges reported between AFL and AI. We conduct a review of the literature to examine the state of work on AFL and AI in the education literature. A review of articles in Web of Science, SCOPUS, and Google Scholar yielded 35 studies for review. We share the trends in research design, AFL conceptions, and AI challenges in the reviewed studies. We offer the implications of AFL and AI and considerations for future research. 
",114,10.1016/j.chbah.2023.100040,2023,,,higher education; university,mali; uk; united kingdom,2024_-_A_review_of_assessment_for_learning_with_artificial_intelligence.pdf
Digital Distractions in Reading: Investigating Impact of Cognitive Control Training on Reading Behavior and Outcomes,dataset; eye movement; eye-tracking; gaze data; saccade,cnn; deep learning; deep learning model; gat; lstm; neural net; neural network; ppo; transformer; transformer model; transformers,processing; r,Eye-tracking; Distraction; Comprehension; Cognitive control,participants; students,22,,emotional state; eye movement; fixation; saccade,quantitative,2,0,1,0,1,0,0,,participants,technology,training,sensitivity to distraction and,,True,True,False,False,False,True,True,0.939,,0.754,,0.72,,0.73,,0.573,,0.881,,0.927,,,True,False,True,True,False,False,False,0.843,True,0.781,True,0.87,True,0.774,True,0.88,True,0.78,True,0.846,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Jayasankar Santhosh; Shrishti Jagtap; Andreas Dengel; Shoya Ishimaru,"
 Characterizing the effects of notifications and pop-ups on reading comprehension, eye movements, and reader experience can deepen our understanding of digital reading behaviors. However, notifications are highly disruptive and can significantly impact reading performance: a challenge not easily mitigated even in controlled lab studies. We experimented (N = 22) to assess the impact of distractions like notifications/pop-ups on reading comprehension, frustration levels, and readability across 10 documents with varied distractions. The collected data include eye-tracking metrics and survey responses. We observed significant disruptions to reading flow, reduced comprehension, and increased frustration among participants with distractions. Furthermore, we examined the impact of cognitive control training on distraction management and comprehension levels, revealing improved comprehension in digital reading environments with distractions. Our findings provide quantitative evidence of the need for notification/pop-up management strategies that minimize disruptions and promote optimal reading experiences, with implications for the design of digital reading interfaces. 
 CCS CONCEPTS • Human-centered computing → HCI theory, concepts and models; Interaction paradigms; • Applied computing → Learning management systems. 
",168,10.1145/3675094.3677591,,,Eye-tracking; Distraction; Comprehension; Cognitive control,university,,2024_-_Digital_Distractions_in_Reading-_Investigating_Impact_of_Cognitive_Control_Training_on_Reading_Behavior_and_Outcomes.pdf
30 PUBLICATIONS 59 CITATIONS SEE PROFILE,dataset; eda; eye-tracking; facial emotion,chatgpt; deep learning; deep learning model; gat; gpt; language model; large language model; lstm; ppo,processing; r,,learners; students; teachers,12,rna,eda; imu,qualitative,4,0,0,0,0,0,2,,students,computational thinking skills,,in the reviewed studies primar,,True,True,False,False,False,True,True,0.926,,0.785,,0.722,,0.713,,0.584,,0.874,,0.913,,,True,False,True,True,False,False,False,0.847,True,0.812,True,0.866,True,0.795,True,0.877,True,0.809,True,0.846,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Zifeng Liu; Xinyue Jiao; Xueyan Gao; Hyunju Oh,"
 Although computational thinking is critical in education, not only to enhance students' problem-solving and logical thinking skills but also to broaden their creativity and understanding of systems design, challenges such as inadequate educational resources, lack of teaching experience, and abstract nature of programming principles continue to hinder the promotion and implementation of high-quality computer science (CS) education. Artificial intelligence (AI) holds promise in addressing these issues. Yet, the specific impact of AI on K-12 CS education has to be discussed. Existing reviews have focused on the broad spectrum of AI applications in education, with relatively little focus on topics related to CS education and programming instruction, with most of these studies focusing on a single type of AI, such as automated evaluation systems or visual programming, and failing to fully cover the various categories of AI, including machine learning, deep learning, and robotics, especially in the K-12 field. The primary goal of this study is to conduct a systematic review of the current literature concerning the role, impact, and constraints of AI in CS education, with a specific focus on K-12 education. The review process follows the PRISMA principle. A total of 24 articles published between 2013 and 2023 were selected, comprehensively reviewed, and analyzed. The coding scheme mainly includes four aspects: (1) Research background, (2) Research design, (3) AI technologies, and (4) Research outcomes and limitations. Each aspect contains specific dimensions to be coded. The study discovered that AI plays a significant role in K-12 CS as learning content and developing programming platforms. These adaptive learning platforms give personalized programming education and real-time feedback, relieving teachers' workload while giving students personalized curricular information tailored to their needs. Additionally, AI is usually used as a data analytics tool to predict student performance. The reviewed articles focus on AI's cognitive and affective impact on students and found positive effects on those variables. At the same time, AI allows for better analysis and utilization of data on student behavior while programming. Limitations in the current reviewed articles on AI in K-12 CS education include insufficient attention to theoretical adoption, ethical concerns, and methodological issues like small sample sizes. This review highlights the critical role of AI in K-12 CS education and illuminates directions for a more personalized, interactive, and practical learning experience in K-12 CS education in the future. Keywords and search strings as in Table  1  were used to search different databases including ProQuest (including ERIC), Scopus, Web of Science, IEEE Xplore, and ACM Digital Library, with the included years limited to 2013 to 2023. We choose this time frame because it represents 
",432,10.18260/1-2--47532,2024,,,elementary school; high school; k-12; middle school; primary school; secondary school,united states,2024_-_How_AI_assisted_K-12_Computer_Science_Education__A_Systematic_Review.pdf
Enhancing Hybrid Learning: The Role of Multimodal Adaptive Feedback in Human-AI Collaboration,biometric data; data collection; eye-tracking; facial expression; heart rate; heart rate variability,gat; ppo,openface; r,Multimodal Feedback; Hybrid Learning Environments; Human-AI Collaboration; Learner Engagement; Personalized Learning; Willingness to Communicate (WtC) 1,learners; participants; students,,,biometric data; emotional state; fixation; heart rate; heart rate variability; stress level,qualitative,1,0,0,0,2,1,1,,learners,the computational power and ad,fully exploring how multimodal,task performance and error red,,True,True,False,False,False,True,True,0.919,,0.781,,0.734,,0.733,,0.57,,0.859,,0.908,,,False,False,True,False,False,False,False,0.836,True,0.822,True,0.87,True,0.796,True,0.864,True,0.813,True,0.833,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Aboulhassane Cisse,"
 This study explores the transformative potential of multimodal adaptive feedback systems in hybrid learning environments, where human and artificial intelligence (AI) capabilities converge to create personalized, engaging, and effective educational experiences. By integrating real-time data from sources such as eye-tracking, emotion recognition, and physiological monitoring, these systems dynamically adapt to learners' cognitive and emotional states. The findings highlight the role of Affective Backchannels (AB) and Conversational Strategies (CS) in enhancing learner engagement, task performance, and willingness to communicate (WtC). The study demonstrates that human-AI collaboration fosters deeper learning interactions by combining human creativity, empathy, and intuition with AI's computational power and scalability. However, challenges such as scalability, diversity, and long-term applicability remain. This research underscores the need for future studies to refine these technologies, address ethical considerations, and explore broader applications in diverse educational contexts, ultimately shaping the future of inclusive and personalized learning. 
",144,10.1145/3027385.3027410,,,Multimodal Feedback; Hybrid Learning Environments; Human-AI Collaboration; Learner Engagement; Personalized Learning; Willingness to Communicate (WtC) 1,lifelong learning; university,,2025_Camera-Ready_-_Workshop_HILAK_-_Enhancing_Hybrid_Learning-_The_Role_of_Multimodal_Adaptive_Feedback_in_Human-AI_Collaboration.pdf
Harnessing Artificial Intelligence in Generative Content for enhancing motivation in learning,training data,chatgpt; deep learning; gat; gpt; language model; large language model; ppo,excel; processing; r; unity,,learners; students; subjects; teachers,,rna,cognitive load; erp; imu,qualitative,1,0,0,0,0,0,2,,students,education being no exception,laboratory conditions,students,,True,True,False,False,False,True,True,0.922,,0.759,,0.72,,0.708,,0.56,,0.86,,0.904,,,False,False,True,True,False,False,False,0.824,True,0.793,True,0.852,True,0.757,True,0.857,True,0.783,True,0.855,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Jiesi Guo; Tingting Li; Michael Noetel; Kewen Liao; Ying Ma; Samuel Greiff,,0,10.1016/j.lindif.2024.102547,2024,,,college; elementary school; higher education; lifelong learning; preschool; university,tonga; uk,2024_-_Harnessing_Artificial_Intelligence_in_Generative_Content_for_enhancing_motivation_in_learning.pdf
Learning theories for artificial intelligence promoting learning processes,dataset; eda; eye tracking,chatgpt; deep learning; deep learning model; gan; gat; gpt; language model; large language model; neural net; neural network; ppo,aws; cohere; processing; r; unity,artificial intelligence; computational modelling; learning processes,learners; students; subjects,,rna,eda; erp; imu,qualitative,1,0,2,1,0,1,0,,children,significant cross-over of conc,surface learning strategies us,unification of learning theori,,True,False,False,False,False,True,True,0.945,,0.747,,0.721,,0.723,,0.551,,0.862,,0.915,,,True,False,False,True,False,True,True,0.846,True,0.787,True,0.856,True,0.772,True,0.876,True,0.782,True,0.85,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,David Gibson; Vitomir Kovanovic; | Dirk Ifenthaler; Sara Dexter; Shihui Feng,"
 This paper discusses a three-level model that synthesizes and unifies existing learning theories to model the roles of artificial intelligence (AI) in promoting learning processes. The model, drawn from developmental psychology, computational biology, instructional design, cognitive science, complexity and sociocultural theory, includes a causal learning mechanism that explains how learning occurs and works across micro, meso and macro levels. The model also explains how information gained through learning is aggregated, or brought together, as well as dissipated, or released and used within and across the levels. Fourteen roles for AI in education are proposed, aligned with the model's features: four roles at the individual or micro level, four roles at the meso level of teams and knowledge communities and six roles at the macro level of cultural historical activity. Implications for research and practice, evaluation criteria and a discussion of limitations are included. Armed with the proposed model, AI developers can focus their work with learning designers, researchers and practitioners to leverage the proposed roles to improve individual learning, team performance and building knowledge communities. 
",175,10.1111/bjet.13341,,,artificial intelligence; computational modelling; learning processes,college; graduate; higher education; university,australia; japan,2022_-_Learning_theories_for_artificial_intelligence_promoting_learning_processes.pdf
Gaze Generation for Avatars Using GANs,data collection; data set; dataset; eye movement; facial expression; gaze data; gaze position; saccade,cnn; convolutional neural network; deep learning; gan; gat; generative adversarial network; gru; machine learning model; ml model; neural net; neural network; ppo; recurrent neural network; rnn; t5,aws; huggingface; processing; pytorch; r; torch; unity; unreal engine,,participants,73,rna,erp; eye movement; fixation; imu; saccade,qualitative,2,2,0,0,0,0,2,,participants,superficially most of the time,publishing their parameters,various methods of handling th,,True,False,False,False,False,True,True,0.927,,0.703,,0.691,,0.691,,0.511,,0.867,,0.902,,,False,False,True,False,False,False,False,0.813,True,0.745,False,0.824,True,0.729,False,0.853,True,0.737,False,0.848,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,David Dembinsky; K O Watanabe; Andreas Dengel; Shoya Ishimaru,"
 The movement of our eyes during conversations plays a crucial role in our communication. Through a mixture of aimed and subconscious control of our gaze, we nonverbally manage turn-taking in conversations and convey information about our state of mind and even neurological disorders. For animated avatars or robots, it is hence of fundamental importance to exhibit realistic eye movement in conversations to withstand the scrutiny of an observer and not fall into the Uncanny Valley. Otherwise, they will be rejected by the observer as unnatural and possibly scary, provoking disapproval of the entire avatar. Although there exist many promising application areas for avatars and great attention has been given to the automatic animation of mouth and facial expressions, the animation of the eyes is often left to simplistic, rule-based models or ignored altogether. In this work, we aim to alleviate this limitation by leveraging Generative Adversarial Networks (GANs), a potent machine-learning approach, to synthesize eye movement. By focusing on a restricted scenario of face-to-monitor interaction, we can concentrate on the eyes, ignoring additional factors such as gestures, body movement, and spatial positioning of conversation partners. Using a recently published dataset on eye movements during conversation, we train two GANs and compare their performance against three statistical models with hand-crafted rules. We subject all five models to statistical analysis, comparing them to the ground-truth data. We find that the GANs produce the best data of the four models that synthesized reasonable eye movement (excluding the best-scoring model for generating absurd movements). Additionally, we perform a user study, comparing each model pairwise against the others based on 73 participants, resulting in a total of 1314 pairwise comparisons. It shows that the GANs achieve acceptance ratings of 55.3% and 43.7%, outperforming the baseline model with an acceptance rate of 34.0%. Although the best model reaches 67.0%, beating our GANs using a set of rules, we argue that this approach will not be feasible once information like emotions or speech is added to the input. 
",331,10.1109/ACCESS.2024.3430835,,,,university,india; japan; mali,2024_-_Gaze_generation_for_avatars_using_gans.pdf
Multimodal composing with generative AI: Examining preservice teachers' processes and perspectives,data collection; eda; training data,chatgpt; gan; gat; gpt; language model; large language model; ppo; stable diffusion,notion; orange; r; unity; zoom,,learners; participants; students; teachers,21,rna,eda; erp; imu,qualitative,1,0,0,1,0,1,1,,students,questions and concerns across,powerpoint,,,True,False,False,False,False,True,True,0.922,,0.733,,0.714,,0.691,,0.538,,0.852,,0.891,,,True,False,True,True,False,False,False,0.824,True,0.775,True,0.835,True,0.755,True,0.847,True,0.761,True,0.875,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Blaine E Smith; Amanda Yoshiko Shimizu; Sarah K Burriss; Melanie Hundley; Emily Pendergrass,,0,10.1016/j.compcom.2024.102896,2024,,,doctoral; graduate; high school; k-12; middle school; secondary education; undergrad; undergraduate; university,india; oman; uk; united states,2025_-_Multimodal_composing_with_generative_AI-_Examining_preservice_teachers’_processes_and_perspectives.pdf
Learning theories for artificial intelligence promoting learning processes,dataset; eda; eye tracking,chatgpt; deep learning; deep learning model; gan; gat; gpt; language model; large language model; neural net; neural network; ppo,aws; cohere; processing; r; unity,artificial intelligence; computational modelling; learning processes,learners; students; subjects,,rna,eda; erp; imu,qualitative,1,0,2,1,0,1,0,,children,significant cross-over of conc,surface learning strategies us,unification of learning theori,,True,False,False,False,False,True,True,0.945,,0.747,,0.721,,0.723,,0.551,,0.862,,0.915,,,True,False,False,True,False,True,True,0.846,True,0.787,True,0.856,True,0.772,True,0.876,True,0.782,True,0.85,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,David Gibson; Vitomir Kovanovic; | Dirk Ifenthaler; Sara Dexter; Shihui Feng,"
 This paper discusses a three-level model that synthesizes and unifies existing learning theories to model the roles of artificial intelligence (AI) in promoting learning processes. The model, drawn from developmental psychology, computational biology, instructional design, cognitive science, complexity and sociocultural theory, includes a causal learning mechanism that explains how learning occurs and works across micro, meso and macro levels. The model also explains how information gained through learning is aggregated, or brought together, as well as dissipated, or released and used within and across the levels. Fourteen roles for AI in education are proposed, aligned with the model's features: four roles at the individual or micro level, four roles at the meso level of teams and knowledge communities and six roles at the macro level of cultural historical activity. Implications for research and practice, evaluation criteria and a discussion of limitations are included. Armed with the proposed model, AI developers can focus their work with learning designers, researchers and practitioners to leverage the proposed roles to improve individual learning, team performance and building knowledge communities. 
",175,10.1111/bjet.13341,,,artificial intelligence; computational modelling; learning processes,college; graduate; higher education; university,australia; japan,2023_-_Learning_theories_for_artificial_intelligence_promoting_learning_processes.pdf
Automatic Classification of Difficulty of Texts From Eye Gaze and Physiological Measures of L2 English Speakers,data collection; data set; dataset; eda; electrodermal activity; electroencephalography; eye movement; eye tracking; gaze data; heart rate; heart rate variability; keystroke; physiological data; pupil dilation; raw data; saccade; sensor data; skin conductance,deep learning; gan; gat; machine learning model; ppo; random forest; support vector machine; svm,excel; pandas; processing; python; r; scikit-learn; scipy; unity,Cognitive load; electrodermal activity; eye-tracking; human-computer interaction; L2 English speakers,learners; participants; students,95,biomarker; illumina; mutation; rna,blink rate; brain activity; cognitive load; eda; electrodermal activity; electroencephalography; erp; eye activity; eye movement; fixation; heart rate; heart rate variability; hrv; imu; physiological data; ppg; pupil dilation; pupil size; respiratory rate; saccade; sensor data; skin conductance; skin temperature,quantitative,2,2,1,0,0,0,0,,learners,cognitive load,using data related to specific,cognitive states,,True,False,False,False,False,True,True,0.942,,0.726,,0.711,,0.718,,0.539,,0.879,,0.922,,,False,True,True,True,False,False,True,0.835,True,0.759,True,0.855,True,0.764,True,0.876,True,0.764,True,0.844,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Javier Melo; Leigh Fernandez,"
 Reading is an essential method for adults to learn new languages, but difficulty reading texts in a foreign language can increase learners' anxiety. Identifying text difficulty from the reader's perspective can aid language learning by tailoring texts to readers' needs. There is little research focusing on L2 speakers or using a multimodal approach, i.e., using multiple sensors, to detect subjective difficulty. In this study (N = 30) we determined L2 speakers' subjective difficulty while reading using language proficiency and objective text difficulty, combined with physiological data. We compared machine learning classifiers combining eye, skin and heart sensor data against models using each modality separately. Additionally, we assessed the effect on model performance of shifting the data to account for delayed physiological responses. The models detected 3 levels of subjective difficulty (low, medium, high) and were evaluated using leave-one-participantout (LoPo) and leave-one-document-out (LoDo) cross-validation. The results showed acceptable levels of generalization to new participants (Acc LoPo = 0.434) and documents (Acc LoDo = 0.521). Combining sensor data from all modalities improved predictions in both LoDo and LoPo cross-validation, compared to each modality in isolation. Shifting the data to account for physiological response delay did not improve model performance compared to not shifting the data. These findings support refining subjective difficulty detection models and their implementation in adaptive language learning systems. Finally, this work contributes to the field of cognitive science and technology by laying the foundation for innovative approaches to cognitive state detection. 
",242,10.1109/ACCESS.2025.3537156,,,Cognitive load; electrodermal activity; eye-tracking; human-computer interaction; L2 English speakers,kindergarten; university,germany; uk,2025_Automatic_Classification_of_Difficulty_of_Texts_from_Eye_Gaze_and_Physiological_Measures_of_L2_English_Speakers.pdf
Teaching CS50 with AI Leveraging Generative Artificial Intelligence in Computer Science Education,eda,chatgpt; gan; gat; gpt; gpt-4; language model; large language model; llm; ppo; transformer,azure; github; numbers; processing; r; unity,AI; artificial intelligence; generative AI; large language models; LLMs,learners; students; teachers,70,rna,eda; erp; imu,quantitative,1,1,0,0,0,1,0,,students,opencourseware,necessarily valuing factual co,on correctness,,True,False,False,False,False,True,True,0.927,,0.714,,0.716,,0.694,,0.525,,0.842,,0.882,,,False,False,True,False,False,False,False,0.829,True,0.771,True,0.832,True,0.753,True,0.855,True,0.756,True,0.866,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Rongxin Liu; Carter Zenke; Charlie Liu; Andrew Holmes; Patrick Thornton; David J Malan,"
 In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-tostudent ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had ""a personal tutor."" Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education. 
 CCS CONCEPTS • Social and professional topics → CS1; • Applied computing → Computer-assisted instruction. 
",229,10.1145/3626252.3630938,,,AI; artificial intelligence; generative AI; large language models; LLMs,university,mali,2024_-_Teaching_CS50_with_AI.pdf
Augmenting Online Meetings with Context-Aware Real-time Music Generation,speech data,bert; gat; gpt; gpt-4; language model; large language model; llm; ppo,processing; r,"CCS Concepts:; Human-centered computing → Human computer interaction (HCI); Collaborative and social computing; Interaction paradigms; User studies Generative AI, Music Generation, Online Meeting, Communication",participants; respondents,14,,bpm,qualitative,3,0,1,0,0,0,0,,participants,music in meetings,,each based on three criteria,,True,False,False,False,False,True,True,0.919,,0.732,,0.694,,0.688,,0.557,,0.859,,0.891,,,True,False,True,True,False,False,False,0.82,True,0.762,True,0.831,True,0.744,False,0.847,True,0.767,True,0.851,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Haruki Suzawa; Ko O Watanabe; Andreas Dengel,"
 As online communication continues to expand, participants often face cognitive fatigue and reduced engagement. Cognitive augmentation, which leverages technology to enhance human abilities, offers promising solutions to these challenges. In this study, we investigate the potential of generative artificial intelligence (GenAI) for real-time music generation to enrich online meetings. We introduce Discussion Jockey 2, a system that dynamically produces background music in response to live conversation transcripts. Through a user study involving 14 participants in an online interview setting, we examine the system's impact on relaxation, concentration, and overall user experience. The findings reveal that AI-generated background music significantly enhances user relaxation (average score: 5.75/9) and concentration (average score: 5.86/9). This research underscores the promise of context-aware music generation in improving the quality of online communication and points to future directions for optimizing its implementation across various virtual environments. 
",139,,2025,,"CCS Concepts:; Human-centered computing → Human computer interaction (HCI); Collaborative and social computing; Interaction paradigms; User studies Generative AI, Music Generation, Online Meeting, Communication",,oman,2025-Augmenting_Online_Meetings_with_Context-Aware_Real-time_Music_Generation.pdf
Appearance-Based Gaze Estimation with Deep Neural Networks: From Data Collection to Evaluation,data collection; dataset; eye movement; eye tracking; gaze data; gaze position,cnn; convolutional neural network; deep learning; deep learning model; efficientnet; gat; neural net; neural network; recurrent neural network; resnet; rnn; t5; transformer; transformers; vgg16,processing; r; zoom,,participants,17,,eye movement,quantitative,2,0,2,0,0,0,0,,users,inexpensive devices such as we,the use of skin electrodes in,,,True,False,False,False,False,True,True,0.932,,0.736,,0.709,,0.705,,0.544,,0.879,,0.916,,,False,False,False,False,False,False,True,0.831,True,0.773,True,0.848,True,0.783,True,0.876,True,0.796,True,0.826,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Ankur Bhatt; Ko Watanabe; Andreas Dengel; Shoya Ishimaru,"
 Gaze estimation is an important factor in human activity and behavior recognition. The technology is used in numerous applications such as human-computer interaction, driver monitoring systems, and surveillance. Gaze estimation can be achieved using different technologies such as wearable devices or cameras. Estimating gaze using a webcam can indeed be more accessible and convenient compared to methods that rely on specific hardware like infrared cameras. In this paper, we propose a data acquisition approach for modeling appearance-based webcam gaze estimation. We implemented an application to capture gaze points using a common webcam. The application asks to click on the circle displayed on the screen, and whenever the circle is clicked, the face image and the pixel coordinates of the circle are stored. From each of the 17 participants, 50 patterns of face images and pixel coordinate information were collected. The gaze estimation models used were VGG16, ResNet50, EfficientNetB7, and EfficientNetB2. In conclusion, the result of the test set is best for VGG16 (four feature extractors) with an error difference of 2.4 cm. To validate our model, we also applied leave-one-participant-out cross-validation and found that the participant with the smallest error difference is 2.533 cm and the largest error difference is 4.759 cm. The study contributes to proposing the data collection method, the best prediction model, and discovering the difficulty of prediction occurs with human individual differences for webcambased gaze estimation. 
",230,10.60401/ijabc.9,2024,,,,chile; hungary; india; japan; mali; morocco,2024_Appearance-Based-Gaze-Estimation-with-Deep-Neural-Networks-From-Data-Collection-to-Evaluation.pdf
Confidence-Aware Learning Assistant,dataset; eda; eeg; electrodermal activity; electroencephalogram; eye movement; eye tracking; eye-tracking; heart rate; heart rate variability; saccade; training data,gat; ppo; random forest; support vector machine; svm,processing; r,,learners; participants; students; subjects,83,rna,eda; eeg; electrodermal activity; electroencephalogram; eye movement; fixation; heart rate; heart rate variability; hrv; imu; saccade,qualitative,2,1,1,0,0,0,0,,learners,confidence or when a learner a,confidence,how much our system improves t,,True,False,False,False,False,True,True,0.931,,0.718,,0.71,,0.702,,0.53,,0.868,,0.904,,,True,True,True,True,False,False,True,0.838,True,0.759,True,0.845,True,0.748,False,0.867,True,0.757,True,0.855,True,,0.7,True,True,False,True,False,True,True,False,True,True,analytic,Shoya Ishimaru; Takanori Maruichi; Andreas Dengel; Koichi Kise,"
 Not only correctness but also self-confidence play an important role in improving the quality of knowledge. Undesirable situations such as confident incorrect and unconfident correct knowledge prevent learners from revising their knowledge because it is not always easy for them to perceive the situations. To solve this problem, we propose a system that estimates self-confidence while solving multiple-choice questions by eye tracking and gives feedback about which question should be reviewed carefully. We report the results of three studies measuring its effectiveness. (1) On a well-controlled dataset with 10 participants, our approach detected confidence and unconfidence with 81 % and 79 % average precision. (  2 ) With the help of 20 participants, we observed that correct answer rates of questions were increased by 14 % and 17 % by giving feedback about correct answers without confidence and incorrect answers with confidence, respectively. (3) We conducted a large-scale data recording in a private school (72 high school students solved 14,302 questions) to investigate effective features and the number of required training samples. INDEX TERMS Eye tracking, in-the-wild study, learning augmentation, self-confidence estimation. 
",182,,2021,,,graduate; graduate students; high school; primary school; undergrad; undergraduate; undergraduate students,japan,2021_CoALA.pdf
Estimating Self-Confidence in Video-Based Learning Using Eye-Tracking and Deep Neural Networks,data collection; dataset; eeg; electroencephalography; eye movement; eye tracking; eye-tracking; facial expression; gaze data; gaze movement; saccade,decision tree; deep learning; gan; gat; lstm; neural net; neural network; ppo; random forest; support vector machine; svm,processing; r,Eye-tracking; learning augmentation; self-confidence estimation,learners; participants; respondents; students; subjects; teachers,,rna,affective computing; eeg; electroencephalography; emotional state; erp; eye movement; fixation; gaze movement; imu; saccade,quantitative,3,2,1,0,0,0,0,,students,deep-learning approaches,shaking,in milliseconds,,True,True,False,False,False,True,True,0.937,,0.764,,0.719,,0.72,,0.565,,0.88,,0.92,,,True,True,False,True,False,False,True,0.848,True,0.801,True,0.867,True,0.787,True,0.88,True,0.802,True,0.843,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Ankur Bhatt; K O Watanabe; Jayasankar Santhosh; Andreas Dengel,"
 Self-confidence is a crucial trait that significantly influences performance across various life domains, leading to positive outcomes by enabling quick decision-making and prompt action. Estimating self-confidence in video-based learning is essential as it provides personalized feedback, thereby enhancing learners' experiences and confidence levels. This study addresses the challenge of self-confidence estimation by comparing traditional machine-learning techniques with advanced deep-learning models. Our study involved a diverse group of thirteen participants (N=13), each of whom viewed and provided responses to seven distinct videos, generating eye-tracking data that was subsequently analyzed to gain insights into their visual attention and behavior. To assess the collected data, we compare three different algorithms: a Long Short-Term Memory (LSTM), a Support Vector Machine (SVM), and a Random Forest (RF), thereby providing a comprehensive evaluation of the data. The achieved outcomes demonstrated that the LSTM model outperformed conventional hand-crafted feature-based methods, achieving the highest accuracy of 76.9% with Leave-One-Category-Out Cross-Validation (LOCOCV) and 70.3% with Leave-One-Participant-Out Cross-Validation (LOPOCV). Our results underscore the superior performance of the deep-learning model in estimating self-confidence in video-based learning contexts compared to hand-crafted featurebased methods. The outcomes of this research pave the way for more personalized and effective educational interventions, ultimately contributing to improved learning experiences and outcomes. 
",204,10.1109/ACCESS.2024.3515838,,,Eye-tracking; learning augmentation; self-confidence estimation,online learning; university,,2024_Estimating_self-confidence_in_video-based_learning_using_eye-tracking_and_deep_neural_networks.pdf
Toward an Interactive Reading Experience: Deep Learning Insights and Visual Narratives of Engagement and Emotion,data collection; data sample; data set; dataset; ecg; eda; eeg; electrodermal activity; emg; emotion detection; eye movement; eye tracking; eye-tracking; facial expression; gaze data; heart rate; motion sensor; physiological data; raw data; saccade; sensor data; skin conductance,alexnet; autoencoder; cnn; convolutional neural network; deep learning; deep learning model; denoising autoencoder; gat; gru; lstm; machine learning model; mobilenet; neural net; neural network; ppo; recurrent neural network; reinforcement learning; resnet; rnn; svm; transformer; transformer model; transformers,notion; processing; r; unity,,learners; participants; students,3,rna,affective computing; cognitive load; ecg; eda; eeg; electrodermal activity; emg; emotional arousal; emotional state; erp; eye movement; fixation; focus level; gsr; heart rate; imu; physiological data; saccade; sensor data; skin conductance; skin temperature,quantitative,2,1,1,0,1,1,1,,students,students,examining the emotional dimens,reading engagement and compreh,,True,True,False,False,False,True,True,0.942,,0.765,,0.724,,0.733,,0.57,,0.884,,0.927,,,True,True,True,True,False,False,False,0.851,True,0.797,True,0.872,True,0.793,True,0.882,True,0.803,True,0.841,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Jayasankar Santhos; Akshay Palimar Pai; Shoya Ishimaru; Jayasankar Santhosh,"
 Engagement and emotion are critical components that significantly influence a reader's experience during a reading task. Despite the crucial role of engagement and emotions in shaping our reading experience, accurately tracking these dynamic states during actual reading remains a significant challenge. This study bridges this gap by detecting engagement and emotion levels during a reading task by leveraging the power of state-of-the-art deep learning models and investigating the correlations between the engagement levels and emotions. An experiment was conducted involving 18 university students reading 14 documents followed by a questionnaire to rate their levels of engagement, valence, and arousal after reading each document. A Tobii 4C eye-tracker with a pro license along with an Empatica E4 wristband were utilized to record behavioral and physiological data from the participants. A range of deep learning models were utilized for computing the engagement, valence, and arousal values, employing both user-independent and userdependent methods. Our investigation revealed distinct yet complementary strengths in two deep learning models: Transformer excelled in user-independent detection of engagement and emotion with an accuracy of 80.38% (engagement), 71.28% (arousal) and 73.98% (valence) while ResNet shined in the user-dependent setting with an accuracy of 93.56% (engagement), 90.62% (arousal) and 88.70% (valence) which highlights the interplay between individual differences and reading dynamics. Intriguingly, we observed strong, document-specific correlations between engagement and emotion states, suggesting that different texts evoke unique affective responses. We developed an interactive dashboard visualizing predicted engagement and emotions, offering real-time feedback and personalized learning possibilities. The dashboard features an engagement gauge that displays the reader's level of engagement based on predicted class probabilities, and an emotion emoji serving as a visual cue that illustrates the predicted emotional state of the reader. This technology can inform the design of dynamic interfaces that adjust to individual reading styles and emotional responses, potentially enhancing comprehension and involvement. INDEX TERMS Digital reading, physiological sensing, eye tracking, deep learning, affective state. 
",317,10.1109/ACCESS.2024.3350745,,,,master's degree; university,,2024_-_Toward_an_interactive_reading_experience-_Deep_learning_insights_and_visual_narratives_of_engagement_and_emotion.pdf
Gaze-Driven Adaptive Learning System With ChatGPT-Generated Summaries,biosignal; data collection; dataset; eda; eye movement; eye tracking; eye-tracking; facial emotion; facial expression; gaze data; physiological data; raw data; saccade; training data,chatgpt; deep learning; deep learning model; gat; gpt; gpt-3; gpt-3.5; gpt-4; language model; large language model; llm; neural net; neural network; ppo; reinforcement learning; resnet; transformer; transformer model; transformers,aws; cohere; processing; r,,learners; participants; students; subjects; teachers,22,,biosignal; blink rate; cognitive load; eda; emotional state; erp; eye movement; fixation; imu; neuroimaging; physiological data; saccade,qualitative,3,3,1,0,1,1,1,,students,educational content,those in the control group,and compared various methods f,,True,True,False,False,False,True,True,0.941,,0.768,,0.727,,0.738,,0.572,,0.885,,0.931,,,True,True,True,True,False,False,True,0.851,True,0.795,True,0.873,True,0.789,True,0.887,True,0.797,True,0.832,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Jayasankar Santhos; Andreas Dengel; Shoya Ishimaru; Jayasankar Santhosh,"
 This work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by DFKI Ethics Committee under Application No. ALS -31/24. 
",30,10.1109/ACCESS.2024.3503059,,,,online learning; university; upper secondary,mali; uk,2024_Gaze-Driven_Adaptive_Learning_System_with_ChatGPT-Generated_Summaries.pdf
Appearance-Based Gaze Estimation with Deep Neural Networks: From Data Collection to Evaluation,data collection; dataset; eye movement; eye tracking; gaze data; gaze position,cnn; convolutional neural network; deep learning; deep learning model; efficientnet; gat; neural net; neural network; recurrent neural network; resnet; rnn; t5; transformer; transformers; vgg16,processing; r; zoom,Based Gaze Estimation with Deep Neural Networks; From Data Collection to Evaluation Appearance-Based Gaze Estimation with Deep Neural Networks; From Data Collection to Evaluation,participants,17,,eye movement,quantitative,2,0,2,0,0,0,0,,users,inexpensive devices such as we,the use of skin electrodes in,,,True,False,False,False,False,True,True,0.933,,0.736,,0.709,,0.704,,0.543,,0.879,,0.916,,,False,False,False,False,False,False,True,0.831,True,0.773,True,0.848,True,0.783,True,0.876,True,0.795,True,0.826,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Ankur Bhatt; Ko Watanabe; Andreas Dengel; Shoya Ishimaru,"
 Gaze estimation is an important factor in human activity and behavior recognition. The technology is used in numerous applications such as human-computer interaction, driver monitoring systems, and surveillance. Gaze estimation can be achieved using different technologies such as wearable devices or cameras. Estimating gaze using a webcam can indeed be more accessible and convenient compared to methods that rely on specific hardware like infrared cameras. In this paper, we propose a data acquisition approach for modeling appearance-based webcam gaze estimation. We implemented an application to capture gaze points using a common webcam. The application asks to click on the circle displayed on the screen, and whenever the circle is clicked, the face image and the pixel coordinates of the circle are stored. From each of the 17 participants, 50 patterns of face images and pixel coordinate information were collected. The gaze estimation models used were VGG16, ResNet50, EfficientNetB7, and EfficientNetB2. In conclusion, the result of the test set is best for VGG16 (four feature extractors) with an error difference of 2.4 cm. To validate our model, we also applied leave-one-participant-out cross-validation and found that the participant with the smallest error difference is 2.533 cm and the largest error difference is 4.759 cm. The study contributes to proposing the data collection method, the best prediction model, and discovering the difficulty of prediction occurs with human individual differences for webcambased gaze estimation. 
",230,10.1145/2968219.2968271,,,Based Gaze Estimation with Deep Neural Networks; From Data Collection to Evaluation Appearance-Based Gaze Estimation with Deep Neural Networks; From Data Collection to Evaluation,,chile; hungary; india; japan; mali; morocco,2024_-_Appearance-based_gaze_estimation_with_deep_neural_networks-_From_data_collection_to_evaluation.pdf
Enhancing Stress Detection for Students: Exploring the Impact of Fine-Tuning and User-Specific Data Calibration in Deep Learning,accelerometer data; data sample; dataset; ecg; eda; eeg; electrodermal activity; electroencephalography; emg; eye movement; heart rate; physiological data; raw data; sensor data; test data; training data,convolutional net; deep learning; deep learning model; gan; gat; knn; lstm; machine learning model; neural net; neural network; ppo; random forest; resnet; svm; transformer; transformer model; transformers,numbers; processing; python; r; unity,,participants; students; subjects,26,,accelerometer; brain activity; ecg; eda; eeg; electrocardiogram; electrodermal activity; electroencephalography; electromyography; emg; erp; eye movement; galvanic skin response; gsr; gyroscope; heart rate; imu; mental workload; physiological data; ppg; sensor data; skin temperature; stress level; wearable sensor,qualitative,3,0,1,0,0,1,0,,students,the necessity of attending mul,objective measurements,between them,,True,False,False,False,False,True,True,0.941,,0.733,,0.713,,0.721,,0.544,,0.88,,0.924,,,True,False,True,False,False,False,False,0.833,True,0.765,True,0.859,True,0.775,True,0.881,True,0.786,True,0.823,True,,0.8,True,True,False,True,True,True,True,False,True,True,analytic,Rashmi Alur Ramachandra; Jayasankar Santhosh; Andreas Dengel; Shoya Ishimaru,"
 This study presents a comprehensive investigation into stress detection among students, focusing on multiple levels of stress assessment. This research aims to shed light on the complexities of stress experienced in educational settings by utilizing a physiological sensing wristband to capture the multifaceted nature of stress responses. A user study was conducted to calculate the cognitive stress levels of a group of 25 participants by recording physiological signals on an Empatica E4 wristband. Along with the relaxed or non-stressed condition, the study employed a range of simple to complex arithmetic tasks designed to elicit three levels of response: 1) slightly stressed or easy level, 2) stressed or medium level, and 3) highly stressed or hard level. Upon the implementation of multiple deep learning models, FCN, ResNet, and LSTM models demonstrated promising outcomes in accurately categorizing the three different stress levels (easy, medium and hard). The models were trained using KFold and Leave-One-Participant-Out (LOPO) cross-validation techniques. To improve the prediction accuracy of LOPO, a fine-tuning or user-specific data calibration approach was utilized. This approach resulted in significant improvements in accuracy for LOPO, with the FCN model achieving a spike to 60% (F1=0.578), the ResNet model reaching 85% (F1=0.846), and the LSTM model achieving an impressive 91% (F1=0.911) accuracy 
",207,,,,,university,,2024_-_Enhancing_stress_detection_for_students-_Exploring_the_impact_of_fine-tuning_and_user-specific_data_calibration_in_deep_learning.pdf
